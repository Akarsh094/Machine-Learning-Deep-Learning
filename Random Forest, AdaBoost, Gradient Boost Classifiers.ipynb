{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "# Akarsh Sahu\n",
    "# 10-30-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Import the data from the website directly: https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header = None, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                 1       2          3   4                   5   \\\n",
       "0  39         State-gov   77516  Bachelors  13       Never-married   \n",
       "1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n",
       "2  38           Private  215646    HS-grad   9            Divorced   \n",
       "3  53           Private  234721       11th   7  Married-civ-spouse   \n",
       "4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                  6              7      8       9     10  11  12  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male  2174   0  40   \n",
       "1    Exec-managerial        Husband  White    Male     0   0  13   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male     0   0  40   \n",
       "3  Handlers-cleaners        Husband  Black    Male     0   0  40   \n",
       "4     Prof-specialty           Wife  Black  Female     0   0  40   \n",
       "\n",
       "              13     14  \n",
       "0  United-States  <=50K  \n",
       "1  United-States  <=50K  \n",
       "2  United-States  <=50K  \n",
       "3  United-States  <=50K  \n",
       "4           Cuba  <=50K  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) There is no header included, but information on column names is here: https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names (Links to an external site.)\n",
    "\n",
    "Scroll to the bottom of that link to see the explanation of the columns. You need to build the column names for your dataframe. It is highly encouraged to not include spaces in column names. Finally, call your target variable (the last column of \">50K\" or \"<=50k\") \"salary\".\n",
    "\n",
    "An easy way to do this is to build a list of column names, and pass those into the .columns() attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'salary']\n",
    "adult_df.columns = list_of_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Check your dataframe shape to verify that you have the correct # of rows and columns. Run the following command:\n",
    "\n",
    "You should get a shape of: (32561, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Drop the 3rd column from the data (it is referred to as \"fnlwgt\" on UCI's website and is not necessary in this homework)\n",
    "\n",
    "e) Note: There are random values of  '?' that show up in the data - this is fine! These just refer to \"unknown\" and can be left as is. This data has no true NA values, so no need to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  education  education-num      marital-status  \\\n",
       "0   39         State-gov  Bachelors             13       Never-married   \n",
       "1   50  Self-emp-not-inc  Bachelors             13  Married-civ-spouse   \n",
       "2   38           Private    HS-grad              9            Divorced   \n",
       "3   53           Private       11th              7  Married-civ-spouse   \n",
       "4   28           Private  Bachelors             13  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital_gain  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male          2174   \n",
       "1    Exec-managerial        Husband  White    Male             0   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male             0   \n",
       "3  Handlers-cleaners        Husband  Black    Male             0   \n",
       "4     Prof-specialty           Wife  Black  Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week native_country salary  \n",
       "0             0              40  United-States  <=50K  \n",
       "1             0              13  United-States  <=50K  \n",
       "2             0              40  United-States  <=50K  \n",
       "3             0              40  United-States  <=50K  \n",
       "4             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_df = adult_df.drop(columns = ['fnlwgt'], axis = 1)\n",
    "adult_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Use the .replace() method to make the following changes to the \"salary\" column:\n",
    "\n",
    "1. \"<=50K\" should become 0\n",
    "2. \">50K\" should become 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_df.salary = adult_df.salary.replace('<=50K', 0)\n",
    "adult_df.salary = adult_df.salary.replace('>50K', 1)\n",
    "adult_df.salary.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g) Create your X dataframe (just your predictors). It should include every feature except for the target variable which is \"salary\".\n",
    "#### h) Create your y dataframe (just your target variable). It should only be \"salary\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  education  education-num      marital-status  \\\n",
       "0   39         State-gov  Bachelors             13       Never-married   \n",
       "1   50  Self-emp-not-inc  Bachelors             13  Married-civ-spouse   \n",
       "2   38           Private    HS-grad              9            Divorced   \n",
       "3   53           Private       11th              7  Married-civ-spouse   \n",
       "4   28           Private  Bachelors             13  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital_gain  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male          2174   \n",
       "1    Exec-managerial        Husband  White    Male             0   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male             0   \n",
       "3  Handlers-cleaners        Husband  Black    Male             0   \n",
       "4     Prof-specialty           Wife  Black  Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week native_country  \n",
       "0             0              40  United-States  \n",
       "1             0              13  United-States  \n",
       "2             0              40  United-States  \n",
       "3             0              40  United-States  \n",
       "4             0              40           Cuba  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = adult_df.salary\n",
    "X = adult_df.drop(columns = ['salary'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 13)\n",
      "(32561,)\n"
     ]
    }
   ],
   "source": [
    "print( X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) For this homework we will try converting columns with factors to separate columns (i.e. one-hot encoding). It is not necessary for trees, but can be a very powerful tool to use. There are a variety of ways to do this, but we can use Pandas built-in method .get_dummies(). Pandas will automatically split out columns that are categorical. For now, just run across your full X dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 107)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_enc = pd.get_dummies(X)\n",
    "X_enc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### j) Split data into train / test set using an 70/30 split. Verify that you have the same number of columns in your X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_enc.to_numpy(), y.to_numpy(), test_size=0.3, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest Classifier - Base Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Use the RandomForestClassifier in sklearn. Fit your model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akars\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mdl1 = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "mdl1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Use the fitted model to predict on test data. Use the .predict_proba() and the .predict() methods to get predicted probabilities as well as predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY_1 = mdl1.predict(X_test)\n",
    "predProb_1 = mdl1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Calculate the confusion matrix and classification report (both are in sklearn.metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      " [[6847  608]\n",
      " [ 921 1393]]\n",
      "\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      7455\n",
      "           1       0.70      0.60      0.65      2314\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      9769\n",
      "   macro avg       0.79      0.76      0.77      9769\n",
      "weighted avg       0.84      0.84      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "\n",
    "#Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, predY_1)\n",
    "print(\"Confusion Matrix\\n\\n\", cnf_matrix)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "#Classification Report\n",
    "cl_report = metrics.classification_report(y_test, predY_1)\n",
    "print(\"Classification Report\\n\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Calculate the AUC score (we did this in HW #4 many times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7602159485289727"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, predY_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Identify the top 5 features. Feel free to print a list OR to make a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdQAAAD8CAYAAADOr1WDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGclJREFUeJzt3Xu0XWV97vHvI2AQLwELdkS8bNQogsEAAUGLRaVapVY8ULEqIlKxtj3WY7GlR2uxHa209kJbrRZtwUsrSBXrKa0CykWRW0ICASuIEE8bHKciknKxKOF3/ljv1sUme2ft7HdfQr6fMdZYc73zne/8rblWeNY712TtVBWSJGlmHjbfBUiS9FBgoEqS1IGBKklSBwaqJEkdGKiSJHVgoEqS1IGBKklSBwaqJEkdGKiSJHWw/XwXoLmz66671tjY2HyXIUlbjVWrVt1WVbuN0tdA3YaMjY2xcuXK+S5DkrYaSb41al9P+UqS1IGBKklSBwaqJEkdGKiSJHVgoEqS1IGBKklSBwaqJEkdGKiSJHVgoEqS1IG/lLQNWbt+A2MnnTvfZUjSnFl3yuFzti9nqJIkdWCgSpLUgYEqSVIHBqokSR0YqJIkdWCgSpLUgYEqSVIHBqokSR0YqAtIks8mWZXk+iQntLbjk9yY5KIkH07y/ta+W5JPJ7mq3Z43v9VL0rbNX0paWN5YVbcneQRwVZJzgd8B9gPuBL4EXNP6/gXw51X1lSRPAr4APHM+ipYkGagLzVuTvLItPxE4Bri4qm4HSHI28PS2/jBgryTj2z4myaOr6s7hAdtM9wSA7R6z2yyXL0nbLgN1gUhyKIOQPLiq7klyEXADk886H9b6fn+qcavqNOA0gEVLlla3giVJD+B3qAvHYuB7LUz3BA4CdgJ+OskuSbYHjhzqfx7wa+MPkiyf02olSQ9goC4cnwe2T3It8PvA5cB64A+BK4ALgK8BG1r/twIrklyb5GvAL899yZKkcZ7yXSCq6l7gpRPbk6ysqtPaDPUcBjNTquo24Oi5rVKSNBlnqAvfyUnWANcBtwCfned6JEmb4Ax1gauqE+e7BknS5jlDlSSpAwNVkqQODFRJkjowUCVJ6sCLkrYhy3ZfzMpTDp/vMiTpIckZqiRJHRiokiR1YKBKktSBgSpJUgcGqiRJHRiokiR1YKBKktSBgSpJUgcGqiRJHRiokiR1YKBKktSBgSpJUgcGqiRJHRiokiR1YKBKktSBgSpJUgcGqiRJHRiokiR1YKBKktSBgSpJUgcGqiRJHWw/3wVo7qxdv4Gxk86d7zKk7tadcvh8lyA5Q5UkqQcDVZKkDgxUSZI6MFAlSerAQJUkqQMDVZKkDgxUSZI6MFBHkOTxSf6xLS9P8rIRtjk0yT93ruNfkuzcc0xJUh8G6giq6taqOqo9XA5sNlBnqY6XVdUd87FvSdLUtolATfL6JNcmuSbJx5O8PMkVSVYnuSDJT7Z+J7f1X0ryjSRvau1jSa5L8nDg94Cjk6xJcnSSA5N8tY311STPGLGm3ZKcn+TqJH+T5FtJdm3rPptkVZLrk5wwtM26JLu2ev4tyYdbn/OSPKL/kZMkjeohH6hJ9gbeCbywqp4N/DrwFeCgqtoXOBP4zaFN9gEOBw4G3p3k8eMrquoHwLuBs6pqeVWdBXwdeH4b693AH45Y2u8CX6qq/YBzgCcNrXtjVe0PrADemuQnNrH9UuADVbU3cAdw5CTP/4QkK5Os3HjPhhFLkyRN17bwW74vBP6xqm4DqKrbkywDzkqyBHg4cMtQ/3+qqu8D309yIXAgsGaK8RcDH02yFChghxHr+ingla2mzyf53tC6tyZ5ZVt+IoPw/O6E7W+pqvG6VgFjm9pJVZ0GnAawaMnSGrE2SdI0PeRnqEAYBN2wvwLeX1XLgDcDOw6tm9h3cyH0+8CFVfUs4OUTxtpcXQ9uTA4FDgMObjPq1ZOMee/Q8ka2jQ9HkrRgbQuB+kXgVeOnTZM8lsGscn1bf+yE/q9IsmPrfyhw1YT1dwKPHno8PNYbplHXV4BXtZpeDOwyNN73quqeJHsCB01jTEnSPHnIB2pVXQ/8AXBxkmuAPwNOBs5O8mXgtgmbXAmcC1wO/H5V3Tph/YXAXuMXJQF/DLw3yaXAdtMo7T3Ai5NcDbwU+DaDsP48sH2SaxnMfi+fxpiSpHmSKr9WG5fkZOCuqvqTOdjXImBjVd2X5GDgg1W1fDb3uWjJ0lpy7KmzuQtpXvj3UDVbkqyqqhWj9PV7t/nzJOBTSR4G/AB40zzXI0maAQN1SFWd3HvMJMcx+F91hl1aVb8K7Nt7f5Kk+WGgzrKqOh04fb7rkCTNrof8RUmSJM0FZ6jbkGW7L2alF29I0qxwhipJUgcGqiRJHRiokiR1YKBKktSBgSpJUgcGqiRJHRiokiR1YKBKktSBgSpJUgcGqiRJHRiokiR1YKBKktSBgSpJUgcGqiRJHRiokiR1YKBKktSBgSpJUgcGqiRJHRiokiR1YKBKktSBgSpJUgfbz3cBmjtr129g7KRz57sM6UHWnXL4fJcgzZgzVEmSOjBQJUnqwECVJKkDA1WSpA4MVEmSOjBQJUnqwECVJKmDBReoScaSXDffdSx0HidJWlgWXKDOhiRz9gMWc7kvSdLCsVADdbskH05yfZLzkjwiyfIklye5Nsk5SXYBSHJRkhVtedck69ryG5KcneT/AOclWZLkkiRrklyX5JDJdp7kriR/muTqJF9Msltrf2qSzydZleTLSfZs7Wck+bMkFwJ/NMmYa5PsnIHvJnl9a/94ksOSbJfkfUmuas/xzUPbvmOo/T2bGPspSVYnOWALj7ckaYYWaqAuBT5QVXsDdwBHAh8Dfquq9gHWAr87wjgHA8dW1QuB1wBfqKrlwLOBNVNs90jg6qraD7h4aF+nAf+zqvYHTgT+emibpwOHVdVvTDLmpcDzgL2Bm4HxQD8IuBw4HthQVQcABwBvSrJHkhe343EgsBzYP8nzxwdN8gzg08BxVXXVxJ0mOSHJyiQrN96zYYqnLEmaiYV6evKWqhoPvFXAU4Gdq+ri1vZR4OwRxjm/qm5vy1cBf5dkB+CzQ+Nvyv3AWW35E8BnkjwKeC5wdpLxfouGtjm7qjZOMeaXgecD3wI+CJyQZHfg9qq6qwXnPkmOav0XMwjSF7fb6tb+qNb+f4HdgH8Cjqyq6ze106o6jcEHARYtWVpT1CdJmoGFOkO9d2h5I7DzFH3v48fPY8cJ6+4eX6iqSxgE2nrg4+OnXEdUbR93VNXyodszN7WvSVzCYFZ6CHAR8B3gKAZBCxAGs9/xsfeoqvNa+3uH2p9WVX/bttkA/DuDma8kaR4t1ECdaAPwvaHvPY9hcCoWYB2wf1s+ikkkeTLwn1X1YeBvgf2m2N/DhsZ6DfCVqvov4JYkv9DGS5Jnj/oEqurfgV2BpVV1M/AVBqeNxwP1C8Bb2gyaJE9P8sjW/sY2QybJ7kke17b5AXAE8Pokrxm1FklSfwv1lO+mHAt8KMlODL6DPK61/wnwqSTHAF+aYvtDgXck+SFwFzDVDPVuYO8kqxiE+dGt/bXAB5O8C9gBOBO4ZhrP4Qpgu7b8ZeC9DIIV4CPAGHB1BueUvwMcUVXnJXkmcFk71XwX8DoGM3eq6u4kPwecn+TuqvqnadQjSeokVX6tNlGSu6rqUfNdR2+LliytJceeOt9lSA/i30PVQpVkVVWtGKXv1nLKV5KkBW1rOuXbXZIreOCVugDHzGR2muQ44NcnNF9aVb+6pWNKkha+bTpQq+o5szDm6cDpvceVJC1snvKVJKkDA1WSpA626VO+25pluy9mpVdTStKscIYqSVIHBqokSR0YqJIkdWCgSpLUgYEqSVIHBqokSR0YqJIkdWCgSpLUgYEqSVIHBqokSR0YqJIkdWCgSpLUgYEqSVIHBqokSR0YqJIkdWCgSpLUgYEqSVIHBqokSR0YqJIkdWCgSpLUgYEqSVIH2893AZo7a9dvYOykc+e7DI1g3SmHz3cJkqbJGaokSR0YqJIkdWCgSpLUgYEqSVIHBqokSR0YqJIkdfCQCNQkb0jy/s5jHpFkr6HHv5fksJ77kCQ9dDwkAnWWHAH8KFCr6t1VdcE81iNJWsC2ikBN8rokVyZZk+RvkmyX5LgkNya5GHjeUN8zkhw19PiuoeXfTLI2yTVJTmltb0pyVWv7dJKdkjwX+HngfW2fTx0eN8mLkqxuY/1dkkWtfV2S9yS5uq3bc5Lns8l+SU5OcuJQv+uSjLXb15N8pLX9fZLDklya5BtJDux6wCVJ07bgAzXJM4GjgedV1XJgI/A64D0MgvRnGJpJTjHOSxnMOp9TVc8G/rit+kxVHdDa/g04vqq+CnwOeEdVLa+qbw6NsyNwBnB0VS1j8GtTbxna1W1VtR/wQeBEJjdqv3FPA/4C2AfYE3gN8FNt2/89wvaSpFm04AMVeBGwP3BVkjXt8f8CLqqq71TVD4CzRhjnMOD0qroHoKpub+3PSvLlJGuB1wJ7b2acZwC3VNWN7fFHgecPrf9Mu18FjE0xzqj9xt1SVWur6n7geuCLVVXA2qm2T3JCkpVJVm68Z8MIu5EkbYmtIVADfLTNFJdX1TOAk4GapP99tOeVJMDDh8bZ1DZnAL/WZpvvAXYcoZ6p3NvuN9J+KznJF9qp449M1W+49mbHTfQHuH/o8f1M8ZvMVXVaVa2oqhXb7bR4M6VLkrbU1hCoXwSOSvI4gCSPBVYDhyb5iSQ7AL8w1H8dgxktwCuAHdryecAbk+w0NA7Ao4Fvt3FeOzTOnW3dRF8HxpI8rT0+Brh4qidQVS9pHwZ+aTPPdR2wX6tvP2CPzfSXJC0QCz5Qq+prwLuA85JcC5wPLGEwS70MuAC4emiTDwM/neRK4DnA3W2czzP4XnRlO3U8/r3l7wBXtHG/PjTOmcA72sVHTx2q57+B44Cz22ni+4EPdXq6nwYe2+p7C3DjZvpLkhaIDL6G07Zg0ZKlteTYU+e7DI3AP98mLQxJVlXVilH6LvgZqiRJWwMDVZKkDgxUSZI6MFAlSerAQJUkqYNJfxBADz3Ldl/MSq8elaRZ4QxVkqQODFRJkjowUCVJ6sBAlSSpAwNVkqQODFRJkjowUCVJ6sBAlSSpAwNVkqQODFRJkjowUCVJ6sBAlSSpAwNVkqQODFRJkjowUCVJ6sBAlSSpAwNVkqQODFRJkjowUCVJ6sBAlSSpAwNVkqQOtp/vAjR31q7fwNhJ5853GVu9daccPt8lSFqAnKFKktSBgSpJUgcGqiRJHRiokiR1YKBKktSBgSpJUgcGqiRJHXQL1CQXJVmxmT5vS7LT0ON/SbJzxxpOTnLiJOu+uoVjrkuy69DjQ5P8c4+xepnqeUuS5sa0AjUDMwnhtwE/CtSqellV3TGD8UZWVc+di/1IkrZNmw3HJGNJ/i3JXwNXA8ckuSzJ1UnOTvKoTWzzwSQrk1yf5D2t7a3A44ELk1zY2n40Y0vy9iTXtdvbJuz7w22s85I8Yny8JF9Lcm2SM4d2v1ebLd/c9jle013t/tAklyQ5p23/oS39kDBxZthqH0vyyCTnJrmmtR09tNk7klzZbk9r2708yRVJVie5IMlPDo3/d5M8n3cmuSHJBcAztqR+SVI/owbJM4CPAT8DHA8cVlX7ASuBt2+i/zuragWwD/DTSfapqr8EbgVeUFUvGO6cZH/gOOA5wEHAm5Ls21YvBT5QVXsDdwBHtvaTgH2rah/gl4eG2xN4CXAg8LtJdthEfQcCvwEsA54K/I/NPP8Lk6xJsgb4yGb6AvwscGtVPbuqngV8fmjdf1XVgcD7gVNb21eAg6pqX+BM4Denej7teL0a2LfVfsBkhSQ5oX24Wbnxng0jlC5J2hKjBuq3qupyBmG3F3BpC5djgSdvov+rklwNrAb2bttM5aeAc6rq7qq6C/gMcEhbd0tVrWnLq4Cxtnwt8PdJXgfcNzTWuVV1b1XdBvwn8JOb2N+VVXVzVW0EPtn2P5UXVNXyqloO/NJm+gKsBQ5L8kdJDqmq4ST75ND9wW35CcAXkqwF3sHgmE31fA5hcLzuqar/Aj43WSFVdVpVraiqFdvttHiE0iVJW2LUQL273Qc4fzxcqmqvqjp+uGOSPYATgRe12eO5wI6bGT9TrLt3aHkjP/5B/8OBDwD7A6uSbL+Z/sNqM49HdR8PPIY7AlTVja2utcB7k7x7kn2NL/8V8P6qWga8mQcer8mez5bWLEmaBdP97vBy4HlD3/3tlOTpE/o8hkEAb2jfBb50aN2dwKM3Me4lwBFtvEcCrwS+PFkR7TvPJ1bVhQxOj+4MPOi73CkcmGSPNs7RDE65bol1wH6tpv2APdry44F7quoTwJ+M92mOHrq/rC0vBta35WNH2O8lwCuTPCLJo4GXb2H9kqROpvXn26rqO0neAHwyyaLW/C7gxqE+1yRZDVwP3AxcOjTEacC/Jvn28PeoVXV1kjOAK1vTR6pqdZKxSUrZDvhEksUMZrd/XlV3JFNNdB/gMuAUBt+hXgKcM+qGE3waeH07/X0VPz4Oy4D3Jbkf+CHwlqFtFiW5gsGHmV9sbScDZydZz+BDyx5T7bQdr7OANcC3mOLDhyRpbqRq2zpzmORQ4MSq+rn5rmWuLVqytJYce+rmO2pK/j1UaduRZFW7yHaz/KUkSZI6mNYp34eCqroIuGhiezsNu2hC8zFVtXYOypIkbeW2uUCdTFU9Z75rkCRtvTzlK0lSBwaqJEkdeMp3G7Js98Ws9ApVSZoVzlAlSerAQJUkqQMDVZKkDgxUSZI6MFAlSerAQJUkqQMDVZKkDgxUSZI6MFAlSerAQJUkqYNt7g+Mb8uS3AncMN91TLArcNt8F7EJ1jW6hVgTWNd0LMSaYGHU9eSq2m2Ujv6W77blhlH/8vxcSbJyodUE1jUdC7EmsK7pWIg1wcKtazKe8pUkqQMDVZKkDgzUbctp813AJizEmsC6pmMh1gTWNR0LsSZYuHVtkhclSZLUgTNUSZI6MFC3Ukl+NskNSW5KctIm1i9KclZbf0WSsaF1v93ab0jyklHHnM26kvxMklVJ1rb7Fw5tc1Ebc027PW6OahpL8v2h/X5oaJv9W603JfnLJJlOTTOs67VDNa1Jcn+S5W3djI7ViHU9P8nVSe5LctSEdccm+Ua7HTvUPqPjtaU1JVme5LIk1ye5NsnRQ+vOSHLL0LFaPp2aZlJXW7dxaN+fG2rfo73e32iv/8Pnqq4kL5jw3vrvJEe0dXNxvN6e5GvttfpikicPrZuV91ZXVeVtK7sB2wHfBJ4CPBy4BthrQp9fAT7Ull8NnNWW92r9FwF7tHG2G2XMWa5rX+DxbflZwPqhbS4CVszDsRoDrptk3CuBg4EA/wq8dK7qmtBnGXBzj2M1jbrGgH2AjwFHDbU/Fri53e/SlneZ6fGaYU1PB5a25ccD3wZ2bo/PGO47l8eqrbtrknE/Bby6LX8IeMtc1jXh9bwd2GkOj9cLhvb3Fn78b3FW3lu9b85Qt04HAjdV1c1V9QPgTOAVE/q8AvhoW/5H4EXtk9srgDOr6t6qugW4qY03ypizVldVra6qW1v79cCOSRZNc/9da5pswCRLgMdU1WU1+Bf9MeCIearrF4FPTnPfM6qrqtZV1bXA/RO2fQlwflXdXlXfA84HfrbD8drimqrqxqr6Rlu+FfhPYKT/SX8265pMe31fyOD1hsHr3/29NWJdRwH/WlX3THP/M6nrwqH9XQ48oS3P1nurKwN167Q78O9Dj/+jtW2yT1XdB2wAfmKKbUcZczbrGnYksLqq7h1qO72dZvqdaZ7SmWlNeyRZneTiJIcM9f+PzYw523WNO5oHB+qWHqtR65rutjM9Xj3emyQ5kMHM6JtDzX/QTi/++RZ8gJtpXTsmWZnk8vHTqgxe3zva670lY/aoa9yrefB7ay6P1/EMZpxTbdvj32I3BurWaVP/kZx4ufZkfabbPld1DVYmewN/BLx5aP1rq2oZcEi7HTNHNX0beFJV7Qu8HfiHJI8ZcczZrGuwMnkOcE9VXTe0fibHatS6prvtTI/XjI93m8l8HDiuqsZnZb8N7AkcwOBU4m9NZ8wOdT2pBr8C9Brg1CRP7TBmj7rGj9cy4AtDzXN2vJK8DlgBvG8z2/Y4Xt0YqFun/wCeOPT4CcCtk/VJsj2wmMH3IZNtO8qYs1kXSZ4AnAO8vqp+NIuoqvXt/k7gHxicOpr1mtpp8e+2fa9iMLN5euv/hKHt5/xYNQ+aQczwWI1a13S3nenxmtF7s30IOhd4V1VdPt5eVd+ugXuB05nbYzV+CpqqupnBd9/7Mvjd2p3b6z3tMXvU1bwKOKeqfjhU75wcrySHAe8Efn7oLNVsvbf6mq8vb71t+Y3BbzDfzOCiovEv9/ee0OdXeeAFLZ9qy3vzwIuSbmZwscBmx5zlunZu/Y/cxJi7tuUdGHy39MtzVNNuwHZt+SnAeuCx7fFVwEH8+EKIl83VsWqPH8bgPyZP6XWsRq1rqO8ZPPiipFsYXDSyS1ue8fGaYU0PB74IvG0TfZe0+wCnAqfM4bHaBVjUlncFvkG7QAc4mwdelPQrc1XXUPvlwAvm+ngx+FDxTdqFZLP93up9m5edeuvwwsHLgBvbm++dre33GHyqA9ix/cO8icFVcMP/4X1n2+4Ghq6I29SYc1UX8C7gbmDN0O1xwCOBVcC1DC5W+gtayM1BTUe2fV4DXA28fGjMFcB1bcz3034kZQ5fw0OByyeMN+NjNWJdBzAI87uB7wLXD237xlbvTQxOr3Y5XltaE/A64IcT3lfL27ovAWtbXZ8AHjVXxwp4btv3Ne3++KExn9Je75va679ojl/DMQYfHh82Ycy5OF4XAP9v6LX63Gy/t3re/KUkSZI68DtUSZI6MFAlSerAQJUkqQMDVZKkDgxUSZI6MFAlSerAQJUkqQMDVZKkDv4/1dv4u9HX1oYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(mdl1.feature_importances_, index=X_enc.columns)\n",
    "plt = feat_importances.nlargest(5).plot(kind='barh')\n",
    "plt.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Using the model from part B, predict for the train data. Look at the classification report for the train data - is there overfitting for the RandomForest model happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY_tr_1 = mdl1.predict(X_train)\n",
    "predProb_tr_1 = mdl1.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      " [[17033   232]\n",
      " [  465  5062]]\n",
      "\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     17265\n",
      "           1       0.96      0.92      0.94      5527\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     22792\n",
      "   macro avg       0.96      0.95      0.96     22792\n",
      "weighted avg       0.97      0.97      0.97     22792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "\n",
    "#Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_train, predY_tr_1)\n",
    "print(\"Confusion Matrix\\n\\n\", cnf_matrix)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "#Classification Report\n",
    "cl_report = metrics.classification_report(y_train, predY_tr_1)\n",
    "print(\"Classification Report\\n\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are clear signs of overfitting as precision, recall, and f1-score are significantly higher in training dataset as compared to test dataset. One of the reasons this might occur is due to lack of hyperparameter tuning which we will do in the next models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AdaBoost Classifier - GridSearch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Use the AdaBoostClassifier along with the GridSearchCV tool. Run the GridSearchCV using the following:\n",
    "\n",
    "1. n_estimators: 100, 200, 300, 400\n",
    "2. learning_rate: 0.2,0.4,0.6,0.8,1, 1.2\n",
    "\n",
    "Use 5 cross-fold and for scoring use \"roc_auc\" (this is the score that will be referenced when identifying the best parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#create a dictionary of parameters \n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'learning_rate': [0.2,0.4,0.6,0.8,1, 1.2]\n",
    "}\n",
    "\n",
    "# create Random Forest model \n",
    "ada_obj=AdaBoostClassifier()\n",
    "\n",
    "# Create gridsearch object with various combinations of parameters\n",
    "ada_Grid = GridSearchCV(ada_obj, param_grid, cv = 5, scoring = 'roc_auc',refit = True, n_jobs=-1, verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  9.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [100, 200, 300, 400], 'learning_rate': [0.2, 0.4, 0.6, 0.8, 1, 1.2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "ada_Grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Use the best estimator from GridSearchCV to predict on test data. Use the .predict_proba() and the .predict() methods to get predicted probabilities as well as predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1.2, 'n_estimators': 400}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_Grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_mdl = ada_Grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY_2 = ada_mdl.predict(X_test)\n",
    "predProb_2 = ada_mdl.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Calculate the confusion matrix and classification report (both are in sklearn.metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      " [[7008  447]\n",
      " [ 807 1507]]\n",
      "\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      7455\n",
      "           1       0.77      0.65      0.71      2314\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      9769\n",
      "   macro avg       0.83      0.80      0.81      9769\n",
      "weighted avg       0.87      0.87      0.87      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, predY_2)\n",
    "print(\"Confusion Matrix\\n\\n\", cnf_matrix)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "#Classification Report\n",
    "cl_report = metrics.classification_report(y_test, predY_2)\n",
    "print(\"Classification Report\\n\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Calculate the AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7956467412947869"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, predY_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Identify the top 5 features. Feel free to print a list OR to make a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(ada_mdl.feature_importances_, index=X_enc.columns)\n",
    "plt = feat_importances.nlargest(5).plot(kind='barh')\n",
    "plt.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Using the model from part (b), predict for the train data. Look at the classification report for the train data - is there overfitting for the best estimator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY_tr_2 = ada_mdl.predict(X_train)\n",
    "predProb_tr_2 = ada_mdl.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      " [[16247  1018]\n",
      " [ 1902  3625]]\n",
      "\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     17265\n",
      "           1       0.78      0.66      0.71      5527\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     22792\n",
      "   macro avg       0.84      0.80      0.82     22792\n",
      "weighted avg       0.87      0.87      0.87     22792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_train, predY_tr_2)\n",
    "print(\"Confusion Matrix\\n\\n\", cnf_matrix)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "#Classification Report\n",
    "cl_report = metrics.classification_report(y_train, predY_tr_2)\n",
    "print(\"Classification Report\\n\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no sign of overfitting as the model metrics of the training dataset are comparable to that of the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradient Boosting Classifier - GridSearch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Use GradientBoostingClassifier along with the GridSearchCV tool. Run the GridSearchCV using the following hyperparameters:\n",
    "\n",
    "1. n_estimators: 100,200, 300 & 400\n",
    "2. learning_rate: choose 3 learning rates of your choice\n",
    "3. max_depth: 1, 2 (you can try deeper, but remember part of the value of boosting stems from minimal complexity of trees)\n",
    "\n",
    "Note: Feel free to try out more parameters, the above is the bare minimum for this assignment.\n",
    "\n",
    "Use 5 cross-fold and for scoring use \"roc_auc\" (this is the score that will be referenced when identifying the best parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#create a dictionary of parameters \n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'learning_rate': [0.2,0.4,0.6,0.8,1, 1.2],\n",
    "    'max_depth': [1,2]\n",
    "}\n",
    "\n",
    "# create Random Forest model \n",
    "gb_obj=GradientBoostingClassifier()\n",
    "\n",
    "# Create gridsearch object with various combinations of parameters\n",
    "gb_Grid = GridSearchCV(gb_obj, param_grid, cv = 5, scoring = 'roc_auc',refit = True, n_jobs=-1, verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 26.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [100, 200, 300, 400], 'learning_rate': [0.2, 0.4, 0.6, 0.8, 1, 1.2], 'max_depth': [1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "gb_Grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Use the best estimator from GridSearchCV to predict on test data. Use the .predict_proba() and the .predict() methods to get predicted probabilities as well as predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 400}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_Grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "print(gb_Grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_mdl = gb_Grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY_3 = gb_mdl.predict(X_test)\n",
    "predProb_3 = gb_mdl.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Calculate the confusion matrix and classification report (both are in sklearn.metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      " [[7031  424]\n",
      " [ 814 1500]]\n",
      "\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      7455\n",
      "           1       0.78      0.65      0.71      2314\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      9769\n",
      "   macro avg       0.84      0.80      0.81      9769\n",
      "weighted avg       0.87      0.87      0.87      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, predY_3)\n",
    "print(\"Confusion Matrix\\n\\n\", cnf_matrix)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "#Classification Report\n",
    "cl_report = metrics.classification_report(y_test, predY_3)\n",
    "print(\"Classification Report\\n\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Calculate the AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7956767977499105"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, predY_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Identify the top 5 features. Feel free to print a list OR to make a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(gb_mdl.feature_importances_, index=X_enc.columns)\n",
    "plt = feat_importances.nlargest(5).plot(kind='barh')\n",
    "plt.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Using the model from part (b), predict for the train data. Look at the classification report for the train data - is there overfitting for the best estimator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY_tr_3 = gb_mdl.predict(X_train)\n",
    "predProb_tr_3 = gb_mdl.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      " [[16388   877]\n",
      " [ 1828  3699]]\n",
      "\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     17265\n",
      "           1       0.81      0.67      0.73      5527\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     22792\n",
      "   macro avg       0.85      0.81      0.83     22792\n",
      "weighted avg       0.88      0.88      0.88     22792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_train, predY_tr_3)\n",
    "print(\"Confusion Matrix\\n\\n\", cnf_matrix)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "#Classification Report\n",
    "cl_report = metrics.classification_report(y_train, predY_tr_3)\n",
    "print(\"Classification Report\\n\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we don't see any significant signs of overfitting as the model metrics of the training and test dataset are comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. XGBoost - RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat 4(a) - 4(f) with xgboost and RandomizedSearchCV.\n",
    "\n",
    "For 4a use the following parameters: \n",
    "\n",
    "1. n_estimators: 100-1000 in increments of 50  (i.e. 100,150,200,.....1000)\n",
    "2. learning_rate: 0.1 - 1.6 in increments of 0.1\n",
    "3. max_depth: 1, 2\n",
    "4. gamma: 0 - 5 in increments of 0.25\n",
    "\n",
    "Note: For parameters with increments please don't feel the need to type each value by hand. There are better ways to handle this. Post in discussion thread if you are struggling.\n",
    "\n",
    "For RandomizedSearchCV make sure to still use cv = 5 and for scoring use \"roc_auc\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/49/b95c037b717b4ceadc76b6e164603471225c27052d1611d5a2e832757945/xgboost-0.90-py2.py3-none-win_amd64.whl (18.3MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\akars\\anaconda3\\lib\\site-packages (from xgboost) (1.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\akars\\anaconda3\\lib\\site-packages (from xgboost) (1.16.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.90\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "xg_obj = xgb.XGBClassifier()\n",
    "\n",
    "param_grid = {\n",
    "        'max_depth': [1,2],\n",
    "        'learning_rate': np.arange(0.1, 1.7, 0.1).tolist(),\n",
    "        'gamma': np.arange(0, 5.25, 0.25).tolist(),\n",
    "        'n_estimators': np.arange(100, 1100, 100).tolist()}\n",
    "\n",
    "xg_Grid = RandomizedSearchCV(xg_obj, param_grid, n_iter=20,\n",
    "                            n_jobs=1, verbose=2, cv=5,\n",
    "                            scoring='roc_auc', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] n_estimators=100, max_depth=1, learning_rate=1.2000000000000002, gamma=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, max_depth=1, learning_rate=1.2000000000000002, gamma=0.5, total=   3.6s\n",
      "[CV] n_estimators=100, max_depth=1, learning_rate=1.2000000000000002, gamma=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, max_depth=1, learning_rate=1.2000000000000002, gamma=0.5, total=   3.8s\n",
      "[CV] n_estimators=100, max_depth=1, learning_rate=1.2000000000000002, gamma=0.5 \n",
      "[CV]  n_estimators=100, max_depth=1, learning_rate=1.2000000000000002, gamma=0.5, total=   4.3s\n",
      "[CV] n_estimators=100, max_depth=1, learning_rate=1.2000000000000002, gamma=0.5 \n",
      "[CV]  n_estimators=100, max_depth=1, learning_rate=1.2000000000000002, gamma=0.5, total=   3.9s\n",
      "[CV] n_estimators=100, max_depth=1, learning_rate=1.2000000000000002, gamma=0.5 \n",
      "[CV]  n_estimators=100, max_depth=1, learning_rate=1.2000000000000002, gamma=0.5, total=   4.1s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=1.4000000000000001, gamma=4.0 \n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=1.4000000000000001, gamma=4.0, total=   6.7s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=1.4000000000000001, gamma=4.0 \n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=1.4000000000000001, gamma=4.0, total=   7.1s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=1.4000000000000001, gamma=4.0 \n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=1.4000000000000001, gamma=4.0, total=   6.7s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=1.4000000000000001, gamma=4.0 \n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=1.4000000000000001, gamma=4.0, total=   5.6s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=1.4000000000000001, gamma=4.0 \n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=1.4000000000000001, gamma=4.0, total=   5.9s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=0.6, gamma=4.0 .....\n",
      "[CV]  n_estimators=700, max_depth=1, learning_rate=0.6, gamma=4.0, total=  30.3s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=0.6, gamma=4.0 .....\n",
      "[CV]  n_estimators=700, max_depth=1, learning_rate=0.6, gamma=4.0, total=  34.8s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=0.6, gamma=4.0 .....\n",
      "[CV]  n_estimators=700, max_depth=1, learning_rate=0.6, gamma=4.0, total=  34.7s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=0.6, gamma=4.0 .....\n",
      "[CV]  n_estimators=700, max_depth=1, learning_rate=0.6, gamma=4.0, total=  36.9s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=0.6, gamma=4.0 .....\n",
      "[CV]  n_estimators=700, max_depth=1, learning_rate=0.6, gamma=4.0, total=  35.5s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.4, gamma=4.0 .....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.4, gamma=4.0, total=  17.2s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.4, gamma=4.0 .....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.4, gamma=4.0, total=  13.1s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.4, gamma=4.0 .....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.4, gamma=4.0, total=  13.5s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.4, gamma=4.0 .....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.4, gamma=4.0, total=  13.2s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.4, gamma=4.0 .....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.4, gamma=4.0, total=  13.2s\n",
      "[CV] n_estimators=300, max_depth=2, learning_rate=1.3000000000000003, gamma=2.75 \n",
      "[CV]  n_estimators=300, max_depth=2, learning_rate=1.3000000000000003, gamma=2.75, total=  19.6s\n",
      "[CV] n_estimators=300, max_depth=2, learning_rate=1.3000000000000003, gamma=2.75 \n",
      "[CV]  n_estimators=300, max_depth=2, learning_rate=1.3000000000000003, gamma=2.75, total=  25.4s\n",
      "[CV] n_estimators=300, max_depth=2, learning_rate=1.3000000000000003, gamma=2.75 \n",
      "[CV]  n_estimators=300, max_depth=2, learning_rate=1.3000000000000003, gamma=2.75, total=  25.6s\n",
      "[CV] n_estimators=300, max_depth=2, learning_rate=1.3000000000000003, gamma=2.75 \n",
      "[CV]  n_estimators=300, max_depth=2, learning_rate=1.3000000000000003, gamma=2.75, total=  25.1s\n",
      "[CV] n_estimators=300, max_depth=2, learning_rate=1.3000000000000003, gamma=2.75 \n",
      "[CV]  n_estimators=300, max_depth=2, learning_rate=1.3000000000000003, gamma=2.75, total=  23.3s\n",
      "[CV] n_estimators=300, max_depth=2, learning_rate=1.1, gamma=2.25 ....\n",
      "[CV]  n_estimators=300, max_depth=2, learning_rate=1.1, gamma=2.25, total=  20.9s\n",
      "[CV] n_estimators=300, max_depth=2, learning_rate=1.1, gamma=2.25 ....\n",
      "[CV]  n_estimators=300, max_depth=2, learning_rate=1.1, gamma=2.25, total=  20.7s\n",
      "[CV] n_estimators=300, max_depth=2, learning_rate=1.1, gamma=2.25 ....\n",
      "[CV]  n_estimators=300, max_depth=2, learning_rate=1.1, gamma=2.25, total=  28.0s\n",
      "[CV] n_estimators=300, max_depth=2, learning_rate=1.1, gamma=2.25 ....\n",
      "[CV]  n_estimators=300, max_depth=2, learning_rate=1.1, gamma=2.25, total=  23.1s\n",
      "[CV] n_estimators=300, max_depth=2, learning_rate=1.1, gamma=2.25 ....\n",
      "[CV]  n_estimators=300, max_depth=2, learning_rate=1.1, gamma=2.25, total=  21.4s\n",
      "[CV] n_estimators=500, max_depth=2, learning_rate=1.5000000000000002, gamma=4.25 \n",
      "[CV]  n_estimators=500, max_depth=2, learning_rate=1.5000000000000002, gamma=4.25, total=  37.4s\n",
      "[CV] n_estimators=500, max_depth=2, learning_rate=1.5000000000000002, gamma=4.25 \n",
      "[CV]  n_estimators=500, max_depth=2, learning_rate=1.5000000000000002, gamma=4.25, total=  44.7s\n",
      "[CV] n_estimators=500, max_depth=2, learning_rate=1.5000000000000002, gamma=4.25 \n",
      "[CV]  n_estimators=500, max_depth=2, learning_rate=1.5000000000000002, gamma=4.25, total=  39.6s\n",
      "[CV] n_estimators=500, max_depth=2, learning_rate=1.5000000000000002, gamma=4.25 \n",
      "[CV]  n_estimators=500, max_depth=2, learning_rate=1.5000000000000002, gamma=4.25, total=  40.0s\n",
      "[CV] n_estimators=500, max_depth=2, learning_rate=1.5000000000000002, gamma=4.25 \n",
      "[CV]  n_estimators=500, max_depth=2, learning_rate=1.5000000000000002, gamma=4.25, total=  47.0s\n",
      "[CV] n_estimators=600, max_depth=1, learning_rate=1.0, gamma=4.75 ....\n",
      "[CV]  n_estimators=600, max_depth=1, learning_rate=1.0, gamma=4.75, total=  34.5s\n",
      "[CV] n_estimators=600, max_depth=1, learning_rate=1.0, gamma=4.75 ....\n",
      "[CV]  n_estimators=600, max_depth=1, learning_rate=1.0, gamma=4.75, total=  34.8s\n",
      "[CV] n_estimators=600, max_depth=1, learning_rate=1.0, gamma=4.75 ....\n",
      "[CV]  n_estimators=600, max_depth=1, learning_rate=1.0, gamma=4.75, total=  41.2s\n",
      "[CV] n_estimators=600, max_depth=1, learning_rate=1.0, gamma=4.75 ....\n",
      "[CV]  n_estimators=600, max_depth=1, learning_rate=1.0, gamma=4.75, total=  35.4s\n",
      "[CV] n_estimators=600, max_depth=1, learning_rate=1.0, gamma=4.75 ....\n",
      "[CV]  n_estimators=600, max_depth=1, learning_rate=1.0, gamma=4.75, total=  40.1s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=0.8, gamma=0.25 ....\n",
      "[CV]  n_estimators=700, max_depth=1, learning_rate=0.8, gamma=0.25, total=  39.8s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=0.8, gamma=0.25 ....\n",
      "[CV]  n_estimators=700, max_depth=1, learning_rate=0.8, gamma=0.25, total=  36.1s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=0.8, gamma=0.25 ....\n",
      "[CV]  n_estimators=700, max_depth=1, learning_rate=0.8, gamma=0.25, total=  34.5s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=0.8, gamma=0.25 ....\n",
      "[CV]  n_estimators=700, max_depth=1, learning_rate=0.8, gamma=0.25, total=  42.0s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=0.8, gamma=0.25 ....\n",
      "[CV]  n_estimators=700, max_depth=1, learning_rate=0.8, gamma=0.25, total=  36.8s\n",
      "[CV] n_estimators=500, max_depth=2, learning_rate=1.1, gamma=4.0 .....\n",
      "[CV]  n_estimators=500, max_depth=2, learning_rate=1.1, gamma=4.0, total=  27.9s\n",
      "[CV] n_estimators=500, max_depth=2, learning_rate=1.1, gamma=4.0 .....\n",
      "[CV]  n_estimators=500, max_depth=2, learning_rate=1.1, gamma=4.0, total=  30.8s\n",
      "[CV] n_estimators=500, max_depth=2, learning_rate=1.1, gamma=4.0 .....\n",
      "[CV]  n_estimators=500, max_depth=2, learning_rate=1.1, gamma=4.0, total=  38.6s\n",
      "[CV] n_estimators=500, max_depth=2, learning_rate=1.1, gamma=4.0 .....\n",
      "[CV]  n_estimators=500, max_depth=2, learning_rate=1.1, gamma=4.0, total=  33.3s\n",
      "[CV] n_estimators=500, max_depth=2, learning_rate=1.1, gamma=4.0 .....\n",
      "[CV]  n_estimators=500, max_depth=2, learning_rate=1.1, gamma=4.0, total=  32.9s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=1.4000000000000001, gamma=3.25 \n",
      "[CV]  n_estimators=700, max_depth=1, learning_rate=1.4000000000000001, gamma=3.25, total=  48.8s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=1.4000000000000001, gamma=3.25 \n",
      "[CV]  n_estimators=700, max_depth=1, learning_rate=1.4000000000000001, gamma=3.25, total=  39.7s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=1.4000000000000001, gamma=3.25 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=700, max_depth=1, learning_rate=1.4000000000000001, gamma=3.25, total=  35.7s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=1.4000000000000001, gamma=3.25 \n",
      "[CV]  n_estimators=700, max_depth=1, learning_rate=1.4000000000000001, gamma=3.25, total=  38.5s\n",
      "[CV] n_estimators=700, max_depth=1, learning_rate=1.4000000000000001, gamma=3.25 \n",
      "[CV]  n_estimators=700, max_depth=1, learning_rate=1.4000000000000001, gamma=3.25, total=  33.8s\n",
      "[CV] n_estimators=900, max_depth=2, learning_rate=0.7000000000000001, gamma=4.25 \n",
      "[CV]  n_estimators=900, max_depth=2, learning_rate=0.7000000000000001, gamma=4.25, total=  59.4s\n",
      "[CV] n_estimators=900, max_depth=2, learning_rate=0.7000000000000001, gamma=4.25 \n",
      "[CV]  n_estimators=900, max_depth=2, learning_rate=0.7000000000000001, gamma=4.25, total= 1.1min\n",
      "[CV] n_estimators=900, max_depth=2, learning_rate=0.7000000000000001, gamma=4.25 \n",
      "[CV]  n_estimators=900, max_depth=2, learning_rate=0.7000000000000001, gamma=4.25, total= 1.0min\n",
      "[CV] n_estimators=900, max_depth=2, learning_rate=0.7000000000000001, gamma=4.25 \n",
      "[CV]  n_estimators=900, max_depth=2, learning_rate=0.7000000000000001, gamma=4.25, total= 1.0min\n",
      "[CV] n_estimators=900, max_depth=2, learning_rate=0.7000000000000001, gamma=4.25 \n",
      "[CV]  n_estimators=900, max_depth=2, learning_rate=0.7000000000000001, gamma=4.25, total= 1.0min\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.8, gamma=4.75 ....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.8, gamma=4.75, total=  15.4s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.8, gamma=4.75 ....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.8, gamma=4.75, total=  13.1s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.8, gamma=4.75 ....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.8, gamma=4.75, total=  13.5s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.8, gamma=4.75 ....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.8, gamma=4.75, total=  12.9s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.8, gamma=4.75 ....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.8, gamma=4.75, total=  13.3s\n",
      "[CV] n_estimators=500, max_depth=1, learning_rate=1.3000000000000003, gamma=2.5 \n",
      "[CV]  n_estimators=500, max_depth=1, learning_rate=1.3000000000000003, gamma=2.5, total=  23.9s\n",
      "[CV] n_estimators=500, max_depth=1, learning_rate=1.3000000000000003, gamma=2.5 \n",
      "[CV]  n_estimators=500, max_depth=1, learning_rate=1.3000000000000003, gamma=2.5, total=  26.7s\n",
      "[CV] n_estimators=500, max_depth=1, learning_rate=1.3000000000000003, gamma=2.5 \n",
      "[CV]  n_estimators=500, max_depth=1, learning_rate=1.3000000000000003, gamma=2.5, total=  26.2s\n",
      "[CV] n_estimators=500, max_depth=1, learning_rate=1.3000000000000003, gamma=2.5 \n",
      "[CV]  n_estimators=500, max_depth=1, learning_rate=1.3000000000000003, gamma=2.5, total=  24.1s\n",
      "[CV] n_estimators=500, max_depth=1, learning_rate=1.3000000000000003, gamma=2.5 \n",
      "[CV]  n_estimators=500, max_depth=1, learning_rate=1.3000000000000003, gamma=2.5, total=  24.0s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=1.5000000000000002, gamma=2.25 \n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=1.5000000000000002, gamma=2.25, total=  13.0s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=1.5000000000000002, gamma=2.25 \n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=1.5000000000000002, gamma=2.25, total=  12.9s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=1.5000000000000002, gamma=2.25 \n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=1.5000000000000002, gamma=2.25, total=  13.8s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=1.5000000000000002, gamma=2.25 \n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=1.5000000000000002, gamma=2.25, total=  16.6s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=1.5000000000000002, gamma=2.25 \n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=1.5000000000000002, gamma=2.25, total=  12.7s\n",
      "[CV] n_estimators=1000, max_depth=2, learning_rate=0.2, gamma=2.25 ...\n",
      "[CV]  n_estimators=1000, max_depth=2, learning_rate=0.2, gamma=2.25, total= 1.2min\n",
      "[CV] n_estimators=1000, max_depth=2, learning_rate=0.2, gamma=2.25 ...\n",
      "[CV]  n_estimators=1000, max_depth=2, learning_rate=0.2, gamma=2.25, total= 1.8min\n",
      "[CV] n_estimators=1000, max_depth=2, learning_rate=0.2, gamma=2.25 ...\n",
      "[CV]  n_estimators=1000, max_depth=2, learning_rate=0.2, gamma=2.25, total= 1.8min\n",
      "[CV] n_estimators=1000, max_depth=2, learning_rate=0.2, gamma=2.25 ...\n",
      "[CV]  n_estimators=1000, max_depth=2, learning_rate=0.2, gamma=2.25, total= 1.8min\n",
      "[CV] n_estimators=1000, max_depth=2, learning_rate=0.2, gamma=2.25 ...\n",
      "[CV]  n_estimators=1000, max_depth=2, learning_rate=0.2, gamma=2.25, total= 1.8min\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.7000000000000001, gamma=0.0 \n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.7000000000000001, gamma=0.0, total=  10.9s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.7000000000000001, gamma=0.0 \n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.7000000000000001, gamma=0.0, total=  10.9s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.7000000000000001, gamma=0.0 \n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.7000000000000001, gamma=0.0, total=  10.9s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.7000000000000001, gamma=0.0 \n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.7000000000000001, gamma=0.0, total=  10.9s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.7000000000000001, gamma=0.0 \n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.7000000000000001, gamma=0.0, total=  11.0s\n",
      "[CV] n_estimators=600, max_depth=1, learning_rate=0.5, gamma=1.25 ....\n",
      "[CV]  n_estimators=600, max_depth=1, learning_rate=0.5, gamma=1.25, total=  48.1s\n",
      "[CV] n_estimators=600, max_depth=1, learning_rate=0.5, gamma=1.25 ....\n",
      "[CV]  n_estimators=600, max_depth=1, learning_rate=0.5, gamma=1.25, total=  48.1s\n",
      "[CV] n_estimators=600, max_depth=1, learning_rate=0.5, gamma=1.25 ....\n",
      "[CV]  n_estimators=600, max_depth=1, learning_rate=0.5, gamma=1.25, total=  48.3s\n",
      "[CV] n_estimators=600, max_depth=1, learning_rate=0.5, gamma=1.25 ....\n",
      "[CV]  n_estimators=600, max_depth=1, learning_rate=0.5, gamma=1.25, total=  48.4s\n",
      "[CV] n_estimators=600, max_depth=1, learning_rate=0.5, gamma=1.25 ....\n",
      "[CV]  n_estimators=600, max_depth=1, learning_rate=0.5, gamma=1.25, total=  48.1s\n",
      "[CV] n_estimators=1000, max_depth=1, learning_rate=0.7000000000000001, gamma=0.5 \n",
      "[CV]  n_estimators=1000, max_depth=1, learning_rate=0.7000000000000001, gamma=0.5, total= 1.3min\n",
      "[CV] n_estimators=1000, max_depth=1, learning_rate=0.7000000000000001, gamma=0.5 \n",
      "[CV]  n_estimators=1000, max_depth=1, learning_rate=0.7000000000000001, gamma=0.5, total= 8.2min\n",
      "[CV] n_estimators=1000, max_depth=1, learning_rate=0.7000000000000001, gamma=0.5 \n",
      "[CV]  n_estimators=1000, max_depth=1, learning_rate=0.7000000000000001, gamma=0.5, total= 1.4min\n",
      "[CV] n_estimators=1000, max_depth=1, learning_rate=0.7000000000000001, gamma=0.5 \n",
      "[CV]  n_estimators=1000, max_depth=1, learning_rate=0.7000000000000001, gamma=0.5, total= 1.4min\n",
      "[CV] n_estimators=1000, max_depth=1, learning_rate=0.7000000000000001, gamma=0.5 \n",
      "[CV]  n_estimators=1000, max_depth=1, learning_rate=0.7000000000000001, gamma=0.5, total= 1.5min\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.8, gamma=1.75 ....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.8, gamma=1.75, total=  28.0s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.8, gamma=1.75 ....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.8, gamma=1.75, total=  25.7s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.8, gamma=1.75 ....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.8, gamma=1.75, total=  25.0s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.8, gamma=1.75 ....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.8, gamma=1.75, total=  25.1s\n",
      "[CV] n_estimators=200, max_depth=2, learning_rate=0.8, gamma=1.75 ....\n",
      "[CV]  n_estimators=200, max_depth=2, learning_rate=0.8, gamma=1.75, total=  20.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed: 63.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "          fit_params=None, iid='warn', n_iter=20, n_jobs=1,\n",
       "          param_distributions={'max_depth': [1, 2], 'learning_rate': [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6, 0.7000000000000001, 0.8, 0.9, 1.0, 1.1, 1.2000000000000002, 1.3000000000000003, 1.4000000000000001, 1.5000000000000002, 1.6], 'gamma': [0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.25, 2.5, 2.75, 3.0, 3.25, 3.5, 3.75, 4.0, 4.25, 4.5, 4.75, 5.0], 'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "xg_Grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Use the best estimator from RandomSearchCV to predict on test data. Use the .predict_proba() and the .predict() methods to get predicted probabilities as well as predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 700, 'max_depth': 1, 'learning_rate': 0.8, 'gamma': 0.25}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_Grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_mdl = xg_Grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY_4 = xg_mdl.predict(X_test)\n",
    "predProb_4 = xg_mdl.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Calculate the confusion matrix and classification report (both are in sklearn.metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      " [[7019  436]\n",
      " [ 825 1489]]\n",
      "\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92      7455\n",
      "           1       0.77      0.64      0.70      2314\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      9769\n",
      "   macro avg       0.83      0.79      0.81      9769\n",
      "weighted avg       0.87      0.87      0.87      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, predY_4)\n",
    "print(\"Confusion Matrix\\n\\n\", cnf_matrix)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "#Classification Report\n",
    "cl_report = metrics.classification_report(y_test, predY_4)\n",
    "print(\"Classification Report\\n\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Calculate the AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7924951321295679"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, predY_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Identify the top 5 features. Feel free to print a list OR to make a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(xg_mdl.feature_importances_, index=X_enc.columns)\n",
    "plt = feat_importances.nlargest(5).plot(kind='barh')\n",
    "plt.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Using the model from part (b), predict for the train data. Look at the classification report for the train data - is there overfitting for the best estimator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY_tr_4 = xg_mdl.predict(X_train)\n",
    "predProb_tr_4 = xg_mdl.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      " [[17033   232]\n",
      " [  465  5062]]\n",
      "\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     17265\n",
      "           1       0.96      0.92      0.94      5527\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     22792\n",
      "   macro avg       0.96      0.95      0.96     22792\n",
      "weighted avg       0.97      0.97      0.97     22792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_train, predY_tr_4)\n",
    "print(\"Confusion Matrix\\n\\n\", cnf_matrix)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "#Classification Report\n",
    "cl_report = metrics.classification_report(y_train, predY_tr_4)\n",
    "print(\"Classification Report\\n\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are signs of overfitting. The difference between the classification reports for Test vs Train is significant (i.e. the accuracy scores are 0.92 vs 0.98, slight difference in other metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Moving into Conceptual Problems:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) What does the alpha parameter represent in AdaBoost? Please refer to chapter 7 of the Hands-On ML book if you are struggling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha = Predictor's weight - The more accurate the predictor is, the higher its weight will be. If it is just guessing randomly, then its weight will be close to zero. However, if it is less accurate than random guessing or mostly wrong, then its weight will be negative. Predictors have different weights depending on their overall accuracy on the weighted training set.\n",
    "\n",
    "Source: Hands on Machine Learning v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) In AdaBoost explain how the final predicted class is determined. Be sure to reference the alpha term in your explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions, AdaBoost computes the predictions of all the predictors and weighs them using the predictor weights α. The predicted class is the one that receives the majority of weighted votes.\n",
    "\n",
    "Steps in detail:\n",
    "\n",
    "1. Each instance weight w is initially set to 1/m -> The first predictor is trained and its weighted error rate r is computed on the training set -> The predictor’s weight α is then computed -> instance weights are updated -> All the instance weights are normalized.\n",
    "\n",
    "2. Finally, a new predictor is trained using the updated weights, and the whole process is repeated (the new predictor’s weight is computed, the instance weights are updated, then another predictor is trained, and so on). The algorithm stops when the desired number of predictors is reached, or when a perfect predictor is found.\n",
    "\n",
    "3. To make predictions, AdaBoost computes the predictions of all the predictors and weighs them using the predictor weights α. The predicted class is the one that receives the majority of weighted votes.\n",
    "\n",
    "Source: Hands on Machine Learning v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) In Gradient Boosting, what is the role of the max_depth parameter? Why is it important to tune on this parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max_depth is the maximum depth of a tree - this indicates how deep the built tree can be. The deeper the tree, the more splits it has and it captures more information about how the data. It is used to control the complexity of the tree, more specifically, it is used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample and usually (should be) tuned using CV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) In Part (e) of Steps 2-5 you determined the top 5 predictors across each model. Do any predictors show up in the top 5 predictors for all three models? If so, comment on if this predictor makes sense given what you are attempting to predict. (Note: If you don't have any predictors showing up across all 3 predictors, explain one that shows up in 2 of them)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Education_Num\" showed up for all the 4 models.\n",
    "\n",
    "No. of years of education is a strong predictor of salary. More educated individual will earn more as compared to less educated individual\n",
    "\n",
    "Also, \"Capital Gain\" came up to be significant in 3 out of 4 models \n",
    "\n",
    "Capital Gain probably has very high predictive power because it is \"income from investment sources, apart from wages / salary\". An individual who is wealthy enough (make enough money from salary, meaning >50k) would participate in investment activities and generate income from those investement activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) From the models run in steps 2-5, which performs the best based on the Classification Report? Support your reasoning with evidence from your test data and be sure to share the optimal hyperparameters found from your grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost, Gradient Boosting and XGBoost all performed pretty well and all had very similar numbers from the Classification Report for the test data. But Gradient Boosting and AdaBoost both performed slightly better than AdaBoost in terms of overfitting and had identical numbers for Precision, Recall and F1-score. So the top performing models for this exercise is: GB and XGB.\n",
    "\n",
    "Optimal hyperparameters for GradBoost:\n",
    "\n",
    "{'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 400}\n",
    "\n",
    "Optimal hyperparameters for AdaBoost:\n",
    "\n",
    "{'learning_rate': 1.2, 'n_estimators': 400}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) For your best performing model, plot out a ROC curve using your test data. Feel free to use sklearn, matplotlib or any other method in python. Describe what the x-axis & y-axis of the ROC curve tell us about a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to select GB as the best performing model for this exercise and plot out the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(predY_3, y_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "lw = 2\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color = 'orange', lw=lw, label = 'ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0,1], color = 'red', lw = lw, linestyle = '--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve illustrates the classification ability of the binary classifier (Gradient Boost in this case) as its discrimination threshold is varied. The x-axis and y-axis are the proportion of correctly classified data points (true positive rate; on the y-axis) and the proportion of \"false positives\" (on the x-axis).\n",
    "\n",
    "For my reference: The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. The true-positive rate is also known as sensitivity, recall or probability of detection. The false-positive rate is also known as the fall-out or probability of false alarm and can be calculated as (1 − specificity)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
