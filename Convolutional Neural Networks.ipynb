{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IGKWiwpNuFv9"
   },
   "source": [
    "# Assignment 8\n",
    "## Submitted by - Akarsh Sahu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "ZQkNd8j0NQaC",
    "outputId": "71d3b29f-e3cf-4ae8-c16c-faf47660d6c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "from keras import models, Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16, ResNet50, VGG19, InceptionV3\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras import optimizers, regularizers\n",
    "from keras.optimizers import SGD\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from keras.models import model_from_yaml\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chHeR211W7tq"
   },
   "outputs": [],
   "source": [
    "#!pip install -U PyYaml==5.1.2\n",
    "#!pip install -U keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "ZzXj9xpJNaFu",
    "outputId": "fba31cee-4502-4345-969b-a27d92e5cee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "dr_path = \"drive/My Drive/ML Assignment 8/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5Kv9uaOOFgk"
   },
   "source": [
    "## 1. Data Processing:\n",
    "\n",
    "The train & test data is pretty clean in terms of image data, but we will need to do a bit of prep work to use in our model.\n",
    "\n",
    "a) Use the \"ImageDataGenerator()\" class from keras.processing.image to build out an instance called \"train_datagen\" with the following parameters:\n",
    "\n",
    "- rescale = 1./255\n",
    "- shear_range = 0.2\n",
    "- zoom_range = 0.2\n",
    "- horizontal_flip = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SqwqlRTzOV7d"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7j7smpRqOcw_"
   },
   "source": [
    "b) Then build your training set by using the method \".flow_from_directory()\"\n",
    "\n",
    "- path (where training data is stored)\n",
    "- target_size = (64, 64)\n",
    "- batch_size = 32\n",
    "- class_mode = categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8xqpg17zOcEM",
    "outputId": "fc5296dc-e0b3-4d7a-ce0d-218f1e2dc1c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_datagen.flow_from_directory(\n",
    "    dr_path + \"dataset_train\",\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKfFNm9uPYlt"
   },
   "source": [
    "c) Take a look at your training set: \n",
    "\n",
    "- What is the image shape of each training observation?\n",
    "- How many total classes do we need to predict on? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_IAROeW3OcA6",
    "outputId": "dbc66a66-e0d0-43e6-910b-dd6d555c8815"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_shape = train_set.image_shape\n",
    "img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JWqlAd1RQjTI",
    "outputId": "17ccfd01-6e32-4c2e-a14f-38706c8f8ed8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category 1': 0, 'category 2': 1, 'category 3': 2, 'category 4': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iZRkYp_9QwVs"
   },
   "source": [
    "## 2. Initial Classifier Build:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "juXh-iuBQ3TY"
   },
   "source": [
    "Now use keras to build an initial image classifier with the following specifications.\n",
    "\n",
    "*Note: If you get lost, there is great documentation online and homework 7 included details on many of the layers used here.*\n",
    "\n",
    "* Create an instance of Sequential called \"classifier\"\n",
    "* Add a Conv2D layer with the following parameters: \n",
    "    1. filters = 32\n",
    "    2. kernel_size = (3,3)\n",
    "    3. input_shape = image shape found in part 1\n",
    "    4. activation = relu\n",
    "* Add a MaxPooling2D layer where pool_size = (2,2)\n",
    "* Add another Conv2D layer: \n",
    "    1. filters = 64\n",
    "    2. kernel_size = (3,3)\n",
    "    3. activation = relu\n",
    "* Add a MaxPooling2D layer where pool_size = (2,2)\n",
    "* Add a Flatten layer\n",
    "* Add a Dense layer\n",
    "    1. units = 128\n",
    "    2. activation = relu\n",
    "* Add a final Dense layer (this will output our probabilities):\n",
    "    1. units = # of classes\n",
    "    2. activation = softmax \n",
    "* Compile with the following: \n",
    "    1. optimize = adam\n",
    "    2. loss = categorical cross entropy\n",
    "    3. metric = accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qrGvSOcVQubu"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  classifier = Sequential()\n",
    "  classifier.add(layers.Conv2D(32, kernel_size = (3,3), activation = 'relu', input_shape = img_shape))\n",
    "  classifier.add(layers.MaxPooling2D(pool_size = (2,2)))\n",
    "  classifier.add(layers.Conv2D(64, kernel_size = (3,3), activation = 'relu'))\n",
    "  classifier.add(layers.MaxPooling2D(pool_size = (2,2)))\n",
    "  classifier.add(layers.Flatten())\n",
    "  classifier.add(layers.Dense(128, activation  = 'relu'))\n",
    "  classifier.add(layers.Dense(4, activation = 'softmax'))\n",
    "\n",
    "  classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "  return classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "JHtCQVz9Qu5b",
    "outputId": "b4422d0d-9a92-4694-9fc5-7f88242a1825"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "colab_type": "code",
    "id": "-u1pxN-ZQu80",
    "outputId": "86f2f3b2-8acb-4035-eec1-710c46fa28d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 1,625,668\n",
      "Trainable params: 1,625,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iM4LLVTKmyBZ"
   },
   "source": [
    "## 3. Model Runs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xzLItNIJm3vh"
   },
   "source": [
    "a) Use .fit_generator() with the training set. For the first run, use the following parameters: \n",
    "\n",
    "- steps_per_epoch = 10\n",
    "- epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "id": "Aj1skrqDm2-k",
    "outputId": "4daca19f-da82-428d-8570-61889809ffe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 1.1047 - accuracy: 0.5903\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 0.2357 - accuracy: 0.9426\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 0.1339 - accuracy: 0.9493\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.0916 - accuracy: 0.9696\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 0.0296 - accuracy: 0.9932\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 0.0257 - accuracy: 0.9931\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.0113 - accuracy: 0.9966\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 3s 263ms/step - loss: 0.0087 - accuracy: 0.9965\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.0061 - accuracy: 0.9965\n"
     ]
    }
   ],
   "source": [
    "model_1 = classifier.fit_generator(train_set, steps_per_epoch=10, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCYxuNFngX4m"
   },
   "source": [
    "b) Write out each model & model_weights to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SZeVLXhdm3Jz",
    "outputId": "38d70bf8-3953-4769-dd60-a800ce0295e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# write model and model weights to disk\n",
    "model_yaml = classifier.to_yaml()\n",
    "with open(\"model_1.yaml\", \"w\") as yaml_file:\n",
    "  yaml_file.write(model_yaml)\n",
    "  \n",
    "  classifier.save_weights(dr_path + \"models/\" + \"model_1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dBBiEtXoAMy"
   },
   "source": [
    "c) Predict using the model built in step 2. An example below shows how to reread weights & model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "JXKagugWmxFd",
    "outputId": "7022a2e3-4789-468c-8832-fee2fd1452de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 0, 1, 1, 1, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model from disk\n",
    "yaml_file = open('model_1.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "model.load_weights(dr_path + \"models/\" + \"model_1.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# test data path\n",
    "img_dir = dr_path + \"dataset_test\" # Enter Directory of all images\n",
    "\n",
    "# iterate over each test image\n",
    "# make a prediction and add to results \n",
    "data_path = os.path.join(img_dir, '*g')\n",
    "files = glob.glob(data_path)\n",
    "data = []\n",
    "results = []\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result = model.predict(img)\n",
    "    r = np.argmax(result, axis=1)\n",
    "    results.append(r)\n",
    "\n",
    "np.concatenate(results).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KarNHs2jn3ts"
   },
   "source": [
    "d) Determine accuracy.\n",
    "\n",
    "*Note: To determine accuracy, you will need to manually check the labels given to each class in the training data. This will require you to go and look in the training data, and then determine how a category was coded in keras.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cMdEeFXgHKUi"
   },
   "source": [
    "1. Category 0 - Pant Shape\n",
    "2. Category 1 - Gift Wrap\n",
    "3. Category 2 - Mask - Darth Vader\n",
    "4. Category 3 - Cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8yOM-TzyIOOF"
   },
   "source": [
    "By Looking at the results manually, the accuracy = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b-24mcGzJGo5"
   },
   "source": [
    "e) Run this process for the following combinations:\n",
    "\n",
    "* (steps_per_epoch: 10, epochs: 10) <- the one we just did \n",
    "* (steps_per_epoch: 10, epochs: 20)\n",
    "* (steps_per_epoch: 10, epochs: 30)\n",
    "* (steps_per_epoch: 30, epochs: 10)\n",
    "* (steps_per_epoch: 30, epochs: 20)\n",
    "* (steps_per_epoch: 30, epochs: 30)\n",
    "* (steps_per_epoch: 50, epochs: 10)\n",
    "* (steps_per_epoch: 50, epochs: 20)\n",
    "* (steps_per_epoch: 50, epochs: 30)\n",
    "* (steps_per_epoch: 50, epochs: 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Xu1sXin4JSPM",
    "outputId": "77c3a212-6863-4e1f-bb43-11dd9d9312e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 3.4788e-05 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 1.8721e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 1.4536e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 1.4732e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 1.3993e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 1.6242e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 6.3255e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 1.7786e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 1.2133e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 2.5954e-05 - accuracy: 1.0000\n",
      "Saved model 1 to disk - Steps - 10, Epochs - 10\n",
      "1\n",
      "Loaded model 1 from disk\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 1.5216e-05 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 1.1607e-05 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 1.2400e-05 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 9.6292e-06 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 1.3458e-05 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 1.5710e-05 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 2.0305e-05 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 1.0398e-05 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 7.4948e-06 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 3s 264ms/step - loss: 7.7977e-06 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 1.1482e-05 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 7.6577e-06 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 5.5265e-06 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 1.6507e-05 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 3s 264ms/step - loss: 2.2193e-05 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 1.2534e-05 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 1.8896e-05 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 1.0592e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 3s 264ms/step - loss: 1.0584e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 5.8134e-06 - accuracy: 1.0000\n",
      "Saved model 1 to disk - Steps - 10, Epochs - 20\n",
      "2\n",
      "Loaded model 2 from disk\n",
      "Epoch 1/30\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 1.3055e-05 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 5.6265e-06 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 7.1703e-06 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 9.2429e-06 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 4.5847e-06 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 1.0929e-05 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 7.0144e-06 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 1.2555e-05 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 6.6482e-06 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 4.5841e-06 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 5.0607e-06 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 1.1933e-05 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 6.1166e-05 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 3s 264ms/step - loss: 1.2971e-05 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 1.8986e-05 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 2.4746e-05 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 8.2140e-06 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 1.6518e-05 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 1.6685e-05 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 8.6698e-06 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 1.4781e-05 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 6.8632e-06 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 3s 263ms/step - loss: 1.5904e-05 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 4.9111e-06 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 5.0547e-06 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 8.2624e-06 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 8.2393e-06 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 6.3273e-06 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 6.9939e-06 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 3s 263ms/step - loss: 5.0108e-06 - accuracy: 1.0000\n",
      "Saved model 1 to disk - Steps - 10, Epochs - 30\n",
      "3\n",
      "Loaded model 3 from disk\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 1.0731e-05 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 7.3713e-06 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 4.0452e-06 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 2.9106e-06 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 7.0064e-06 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 4.3348e-06 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 3.2618e-06 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 5.3327e-06 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 2.7560e-06 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 4.1670e-05 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 3.0687e-06 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 1.1012e-05 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 7.5697e-06 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 6.7561e-06 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 5.2559e-06 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 5.2878e-06 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 2.8473e-06 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 3s 264ms/step - loss: 2.5985e-06 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 5.6472e-06 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 2.5214e-06 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 1.0902e-05 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 6.0355e-06 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 6.8214e-06 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 3.5375e-06 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 4.4640e-06 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 2.5948e-06 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 7.0197e-06 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 6.1392e-06 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 5.2240e-06 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 4.7348e-06 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 7.2939e-06 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 3.7303e-06 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 6.6091e-06 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 2.7446e-06 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 4.5789e-06 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 4.3137e-06 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 1.5197e-06 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 3.8428e-06 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 1.5365e-06 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 2.2012e-06 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 1.0719e-05 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 4.8332e-06 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 4.0886e-06 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 6.3042e-06 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 1.8146e-06 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 1.9737e-06 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 3s 264ms/step - loss: 1.0694e-05 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 1.3697e-06 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 1.2813e-06 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 7.2370e-06 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 2.7486e-06 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 5.3051e-06 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 2.0568e-06 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 3.6338e-06 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 2.4475e-06 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 3.6479e-06 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 3s 264ms/step - loss: 2.1261e-06 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 2.6481e-06 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 2.7505e-06 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 2.0248e-06 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 1.2205e-06 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 2.1040e-06 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 1.5952e-06 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 4.2370e-05 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 9.8592e-06 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 4.8312e-06 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 1.3972e-05 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 5.0579e-05 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 6.8363e-06 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 1.2783e-06 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 5.3745e-06 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 2.1964e-06 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 2.0347e-06 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 1.4317e-05 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 2.4231e-06 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 7.4833e-06 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 1.9923e-06 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 3.2954e-06 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 1.9307e-06 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 4.3162e-06 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 1.5433e-06 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 2.1287e-06 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 2.7662e-06 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 1.9688e-06 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 1.1003e-06 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 2.1868e-06 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 2.1810e-06 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 3.9434e-06 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 1.5889e-06 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 1.3042e-06 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 3.2155e-06 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 1.6751e-06 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 1.2565e-06 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 1.3772e-06 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 1.1411e-06 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 1.1894e-06 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 3.5700e-06 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 1.0841e-06 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 1.0161e-06 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 1.5585e-06 - accuracy: 1.0000\n",
      "Saved model 1 to disk - Steps - 10, Epochs - 100\n",
      "4\n",
      "Loaded model 4 from disk\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 8s 265ms/step - loss: 1.3703e-06 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 1.4458e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 8s 264ms/step - loss: 2.7680e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.8360e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 8s 269ms/step - loss: 1.5601e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 1.0456e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.3789e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 9.0038e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 2.0057e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 1.2704e-06 - accuracy: 1.0000\n",
      "Saved model 1 to disk - Steps - 30, Epochs - 10\n",
      "5\n",
      "Loaded model 5 from disk\n",
      "Epoch 1/20\n",
      "30/30 [==============================] - 8s 265ms/step - loss: 1.6730e-06 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.4265e-06 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.1870e-06 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 1.5327e-06 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 9.9733e-07 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.2181e-06 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 1.2668e-06 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 9.9070e-07 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 1.1755e-06 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 8s 264ms/step - loss: 1.3534e-06 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 1.0106e-06 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 7.6471e-07 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 6.0778e-07 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 5.2569e-07 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.4393e-06 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 5.8371e-07 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 6.2132e-07 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 1.9108e-06 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 5.3921e-07 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 1.2253e-06 - accuracy: 1.0000\n",
      "Saved model 1 to disk - Steps - 30, Epochs - 20\n",
      "6\n",
      "Loaded model 6 from disk\n",
      "Epoch 1/30\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 8.5307e-07 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.0610e-06 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 9.1652e-07 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 1.0329e-06 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 9.6454e-07 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 5.8813e-07 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 8.3723e-07 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 8.9608e-07 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 6.2650e-07 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 5.3366e-07 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 7.3222e-07 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 6.3302e-07 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 1.6244e-06 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 3.6185e-07 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 5.5936e-07 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 8.4055e-07 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "30/30 [==============================] - 8s 264ms/step - loss: 1.0299e-06 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 5.5838e-07 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 3.3834e-07 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 9.6245e-07 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 3.8308e-07 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 3.5525e-07 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 5.9941e-07 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 6.3595e-07 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 4.4340e-07 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 4.9417e-07 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 5.2761e-07 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 4.6875e-07 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 5.0874e-07 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 4.5543e-07 - accuracy: 1.0000\n",
      "Saved model 1 to disk - Steps - 30, Epochs - 30\n",
      "7\n",
      "Loaded model 7 from disk\n",
      "Epoch 1/100\n",
      "30/30 [==============================] - 8s 265ms/step - loss: 4.2473e-07 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.0386e-06 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 3.4583e-07 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 8s 269ms/step - loss: 5.4086e-07 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 4.1356e-07 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 3.9050e-07 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 4.3304e-07 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 8s 263ms/step - loss: 2.4059e-07 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 2.9346e-07 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 4.4965e-07 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 6.3576e-07 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.9147e-07 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 4.2963e-07 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 4.2502e-07 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 3.4377e-07 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 3.3092e-07 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 3.2101e-07 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 8s 264ms/step - loss: 2.9531e-07 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 4.4189e-07 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 2.8765e-07 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 4.3412e-07 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 2.2066e-07 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 2.0865e-07 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.3181e-07 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 4.1321e-07 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.5962e-07 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 8s 265ms/step - loss: 3.0866e-07 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 2.9359e-07 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 8s 254ms/step - loss: 1.4295e-07 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 8s 262ms/step - loss: 1.7134e-07 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 3.3889e-07 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 2.2123e-07 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 8s 264ms/step - loss: 1.8696e-07 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 8s 265ms/step - loss: 3.2145e-07 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 2.9610e-07 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 2.3188e-07 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 3.7477e-07 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 2.6520e-07 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.9624e-07 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 3.4364e-07 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 8s 263ms/step - loss: 1.7585e-07 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 8s 264ms/step - loss: 1.2170e-07 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 4.2096e-07 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 2.7939e-07 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.2486e-07 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 1.7756e-07 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 1.9168e-07 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 2.3846e-07 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 8s 264ms/step - loss: 1.9329e-07 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.0418e-07 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 8s 264ms/step - loss: 4.2698e-07 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.2908e-07 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.6427e-07 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 3.0148e-07 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 2.2658e-07 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.5907e-07 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.7576e-07 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 2.1513e-07 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 1.2230e-07 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.0885e-07 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 1.7848e-07 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.3745e-07 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 1.8350e-07 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 8s 265ms/step - loss: 1.2610e-07 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 1.4170e-07 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 9.3493e-08 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.6432e-07 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 9.0553e-08 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 8.3691e-08 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 8s 265ms/step - loss: 1.0942e-07 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 7.5093e-08 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 1.1664e-07 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.2593e-07 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 6.4886e-08 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 1.4490e-07 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 3.1460e-07 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.0342e-07 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 9.3726e-08 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 8s 269ms/step - loss: 1.1275e-07 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 8.1260e-08 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.0325e-07 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.0461e-07 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 9.6780e-08 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 9.7341e-08 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 8.6016e-08 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 5.2913e-07 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 2.6715e-07 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 8s 263ms/step - loss: 1.4152e-07 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 1.0085e-07 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.1472e-07 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 9.0405e-08 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 9.8924e-08 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 6.2452e-08 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 1.0840e-07 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 8s 266ms/step - loss: 8.0846e-08 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 1.0817e-07 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 8s 265ms/step - loss: 1.6209e-07 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 2.4752e-07 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 6.7959e-08 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 6.2713e-08 - accuracy: 1.0000\n",
      "Saved model 1 to disk - Steps - 30, Epochs - 100\n",
      "8\n",
      "Loaded model 8 from disk\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 5.4861e-08 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.9812e-08 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 5.2663e-08 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 4.6218e-08 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 5.7499e-08 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 4.9147e-08 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 4.1857e-08 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 7.3583e-08 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 3.8338e-08 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 6.1360e-08 - accuracy: 1.0000\n",
      "Saved model 1 to disk - Steps - 50, Epochs - 10\n",
      "9\n",
      "Loaded model 9 from disk\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 5.5275e-08 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 6.2691e-08 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 5.0427e-08 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 2.9101e-08 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 13s 270ms/step - loss: 3.9916e-08 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 6.9413e-08 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 5.5393e-08 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 14s 270ms/step - loss: 7.4777e-08 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 3.9967e-08 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 14s 273ms/step - loss: 2.9680e-08 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 5.3404e-08 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 4.9989e-08 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 3.7828e-08 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 14s 271ms/step - loss: 4.1011e-08 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 13s 264ms/step - loss: 5.2053e-08 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 4.8991e-08 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.1267e-08 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 2.4563e-08 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 2.5395e-08 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 3.5212e-08 - accuracy: 1.0000\n",
      "Saved model 1 to disk - Steps - 50, Epochs - 20\n",
      "10\n",
      "Loaded model 10 from disk\n",
      "Epoch 1/30\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 2.8157e-08 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 3.0662e-08 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 2.5796e-08 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.9848e-08 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 2.5418e-08 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 3.1089e-08 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 1.8426e-08 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 1.5006e-08 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 3.2904e-08 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 6.0129e-08 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.3378e-08 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 3.0114e-08 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 1.4749e-08 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 2.7480e-08 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 3.1309e-08 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 1.9334e-08 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.2794e-08 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 2.4548e-08 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.9754e-08 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 1.8730e-08 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 2.3347e-08 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 3.4684e-08 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 2.0984e-08 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 1.3928e-08 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 1.4694e-08 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.7954e-08 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 1.0663e-08 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 1.1369e-08 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 1.0997e-08 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 9.8918e-09 - accuracy: 1.0000\n",
      "Saved model 1 to disk - Steps - 50, Epochs - 30\n",
      "11\n",
      "Loaded model 11 from disk\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 1.1646e-08 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 14s 271ms/step - loss: 1.2140e-08 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 7.4530e-09 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 1.2545e-08 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 9.2184e-09 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 9.7531e-09 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 8.9913e-09 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 8.3933e-09 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 5.7314e-09 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 6.9477e-09 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.3060e-08 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 1.0943e-08 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.1565e-08 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 1.2148e-08 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 7.5260e-09 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 7.4757e-09 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 1.7871e-08 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 1.1560e-08 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 1.8421e-08 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 8.9141e-09 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 7.3444e-09 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 8.2488e-09 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 5.9633e-09 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 5.8109e-09 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 7.9439e-09 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 3.9512e-09 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 3.3784e-09 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 7.4011e-09 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 13s 270ms/step - loss: 4.5219e-09 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 5.4392e-09 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 4.5949e-09 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 6.9815e-09 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 7.9195e-09 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.9062e-09 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 3.1071e-09 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 3.0296e-09 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 8.5011e-09 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 4.8464e-09 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 5.8125e-09 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 5.2698e-09 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 3.9480e-09 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 6.8966e-09 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 3.9269e-09 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 3.2567e-09 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 4.5251e-09 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 5.7410e-09 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.9805e-09 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 13s 262ms/step - loss: 4.9411e-09 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 1.8110e-09 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 5.2121e-09 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 3.5517e-09 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.3091e-09 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.9533e-09 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 3.3034e-09 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 2.1871e-09 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 5.5923e-09 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 1.8139e-09 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 4.2265e-09 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 4.1416e-09 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 2.3364e-09 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 1.6112e-09 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 2.7326e-09 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 3.3800e-09 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.1095e-09 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 2.5571e-09 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 3.3736e-09 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 1.6649e-09 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 1.8888e-09 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 2.5555e-09 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 4.2482e-09 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 1.8626e-09 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 2.3123e-09 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 1.8904e-09 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 1.5350e-09 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 4.8892e-09 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 3.5293e-09 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 1.8597e-09 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 1.5900e-09 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 1.6160e-09 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 1.4379e-09 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 1.2169e-09 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 1.3875e-09 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 2.3364e-09 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 1.6373e-09 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 1.3176e-09 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 2.1125e-09 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 1.7120e-09 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 1.3922e-09 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 1.5415e-09 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.3591e-09 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 8.6975e-10 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 1.2170e-09 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 1.4667e-09 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 8.9401e-10 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 2.2117e-09 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 6.7018e-10 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 1.1666e-09 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 1.1912e-09 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 5.2243e-10 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 1.1925e-09 - accuracy: 1.0000\n",
      "Saved model 1 to disk - Steps - 50, Epochs - 100\n",
      "12\n",
      "Loaded model 12 from disk\n"
     ]
    }
   ],
   "source": [
    "steps_iter = np.arange(10, 60, 20)\n",
    "epochs_iter = np.array([10,20,30,100])\n",
    "\n",
    "#steps_iter = np.arange(10, 20, 10)\n",
    "#epochs_iter = np.array([10,20])\n",
    "\n",
    "iter = 1\n",
    "final_result = []\n",
    "\n",
    "for steps in steps_iter:\n",
    "  for epochs in epochs_iter:\n",
    "    model = classifier.fit_generator(train_set, steps_per_epoch=steps, epochs = epochs)\n",
    "\n",
    "    # write model and model weights to disk\n",
    "    model_yaml = classifier.to_yaml()\n",
    "    with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "      yaml_file.write(model_yaml)\n",
    "\n",
    "\n",
    "\n",
    "      classifier.save_weights(dr_path + \"models/\" + \"model_\" + str(iter) + \".h5\")\n",
    "    print(\"Saved model {} to disk - Steps - {}, Epochs - {}\".format(1, steps, epochs))\n",
    "    \n",
    "    # Prediction\n",
    "\n",
    "    # load model from disk\n",
    "    yaml_file = open('model.yaml', 'r')\n",
    "    loaded_model_yaml = yaml_file.read()\n",
    "    yaml_file.close()\n",
    "    model = model_from_yaml(loaded_model_yaml)\n",
    "    print(iter)\n",
    "    # load weights into new model\n",
    "    model.load_weights(dr_path + \"models/\" + \"model_\" + str(iter) + \".h5\")\n",
    "    print(\"Loaded model {} from disk\".format(iter))\n",
    "\n",
    "    # test data path\n",
    "    img_dir = dr_path + \"dataset_test\" # Enter Directory of all images\n",
    "\n",
    "    # iterate over each test image\n",
    "    # make a prediction and add to results \n",
    "    data_path = os.path.join(img_dir, '*g')\n",
    "    files = glob.glob(data_path)\n",
    "    data = []\n",
    "    results = []\n",
    "    for f1 in files:\n",
    "        img = image.load_img(f1, target_size = (64, 64))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis = 0)\n",
    "        data.append(img)\n",
    "        result = model.predict(img)\n",
    "        r = np.argmax(result, axis=1)\n",
    "        results.append(r)\n",
    "    final_result.append(results)\n",
    "\n",
    "    iter = iter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFWPYgC_7W_q"
   },
   "outputs": [],
   "source": [
    "## Save Final Results on Drive\n",
    "final_result_1 = pd.DataFrame(final_result)\n",
    "final_result_1.to_csv(dr_path + \"test_result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhPJ3TPud5ja"
   },
   "source": [
    "f) Create a final dataframe that combines the accuracy across each combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "1hzIFM6ygzU5",
    "outputId": "31d6a2ec-202a-44c4-a6ea-bbee6ffeaba8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAToAAADnCAYAAACOlZoZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img_dir = dr_path + \"dataset_test\" \n",
    "data_path = os.path.join(img_dir, '*g')\n",
    "files = glob.glob(data_path)\n",
    "files\n",
    "\n",
    "import cv2\n",
    "def read_image(path):\n",
    "  image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  return image\n",
    "\n",
    "for x in range(8):\n",
    "  plt.subplot(3, 3, x+1)\n",
    "  image = read_image(files[x])\n",
    "  plt.imshow(image)\n",
    "  plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vbU9xsG8is1D"
   },
   "source": [
    "1. Category 0 - Pant Shape\n",
    "2. Category 1 - Gift Wrap\n",
    "3. Category 2 - Mask - Darth Vader\n",
    "4. Category 3 - Cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM1pKj13lL3i"
   },
   "source": [
    "Looking at the test images, here are the true/actual categories:\n",
    "\n",
    "* Test_1 - Category 0\n",
    "* Test_2 - Category 2\n",
    "* Test_3 - Category 2\n",
    "* Test_4 - Category 0\n",
    "* Test_5 - Category 1\n",
    "* Test_6 - Category 1\n",
    "* Test_7 - Category 3\n",
    "* Test_8 - Category 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "id": "TuQs-5zRjGQa",
    "outputId": "b0b38d31-2372-49cc-e095-f69c4c7a56f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Steps_Per_Epoch</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Test_1</th>\n",
       "      <th>Test_2</th>\n",
       "      <th>Test_3</th>\n",
       "      <th>Test_4</th>\n",
       "      <th>Test_5</th>\n",
       "      <th>Test_6</th>\n",
       "      <th>Test_7</th>\n",
       "      <th>Test_8</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Steps_Per_Epoch  Epochs Test_1  ... Test_6 Test_7 Test_8 Accuracy\n",
       "0       0               10      10    [0]  ...    [1]    [1]    [3]     0.75\n",
       "1       1               10      20    [0]  ...    [1]    [1]    [3]     0.75\n",
       "2       2               10      30    [0]  ...    [1]    [1]    [3]     0.75\n",
       "3       3               10     100    [0]  ...    [1]    [1]    [3]     0.75\n",
       "4       4               30      10    [0]  ...    [1]    [1]    [3]     0.75\n",
       "5       5               30      20    [0]  ...    [1]    [1]    [3]     0.75\n",
       "6       6               30      30    [0]  ...    [1]    [1]    [3]     0.75\n",
       "7       7               30     100    [0]  ...    [1]    [1]    [3]     0.75\n",
       "8       8               50      10    [0]  ...    [1]    [1]    [3]     0.75\n",
       "9       9               50      20    [0]  ...    [1]    [1]    [3]     0.75\n",
       "10     10               50      30    [0]  ...    [1]    [1]    [3]     0.75\n",
       "11     11               50     100    [0]  ...    [1]    [1]    [3]     0.75\n",
       "\n",
       "[12 rows x 12 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Final Output Table\n",
    "test_result = pd.read_csv(dr_path + \"test_result.csv\")\n",
    "colname = ['Test_'+ str(x) for x in num]\n",
    "colname.insert(0, \"Model\")\n",
    "test_result.columns = colname\n",
    "\n",
    "test_result.insert(1,\"Steps_Per_Epoch\" ,[10, 10, 10, 10, 30, 30, 30, 30, 50, 50, 50, 50])\n",
    "test_result.insert(2,\"Epochs\" ,[10, 20, 30, 100, 10, 20, 30, 100,10, 20, 30, 100])\n",
    "\n",
    "test_result.insert(len(test_result.columns), \"Accuracy\", [0.75]*12)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DQop6VjIoJaK"
   },
   "source": [
    "## Conceptual Questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1n7uX2VUoMew"
   },
   "source": [
    "#### 4. Discuss the effect of the following on accuracy and loss (train & test): \n",
    "\n",
    "* Increasing the steps_per_epoch\n",
    "* Increasing the number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2piIxGmoMcY"
   },
   "source": [
    "* Increasing the steps_per_epoch\n",
    "  - Higher steps_per_epoch --> Higher Accuracy in train and test set\n",
    "\n",
    "* Increasing the number of epochs\n",
    "  - Higher number of epochs --> Higher Accuracy in train but lower accuracy in test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f0lBNJ2ooMXg"
   },
   "source": [
    "#### 5. Name two uses of zero padding in CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8jS4y5w6oMT3"
   },
   "source": [
    "Zero-padding refers to the process of symmetrically adding zeroes to the input matrix. It’s a commonly used modification that allows the size of the input to be adjusted to our requirement. It is mostly used in designing the CNN layers when the dimensions of the input volume need to be preserved in the output volume.\n",
    "\n",
    "It is a generic way to \n",
    "1. Control the shrinkage of dimension after applying filters larger than 1x1, and \n",
    "2. Avoid loosing information at the boundaries, e.g. when weights in a filter drop rapidly away from its center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqR-1LVMqGno"
   },
   "source": [
    "#### 6. What is the use of a 1 x 1 kernel in CNN? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwivl0LAqHno"
   },
   "source": [
    "A 1x1 convolution can increase or decrease the number of effective kernels by doing a weighted sum of responses in a depth column at any location on the feature map. A depth column is a set of feature responses at the same position but on different feature maps. That is, at any given position of the input feature map, a depth column is a response vector of different kernels.\n",
    "\n",
    "The 1x1 conv thus samples a depth column at each location on the feature map and does a weighted sum of that vector, with some non-linearity, to produce a new set of responses at that location. Given that a depth column is of dimensionality d and the new set of responses of dimensionality k then if k>d then we have dimensionality increase otherwise we have dimensionality reduction.\n",
    "\n",
    "For example, if we have 10 3x3 kernels convolving over an input feature map, the output from such a layer would be of depth 10 and a 1x1 convolution operation on the output from such a layer will only sample depth-wise which means it gets a depth column of dimensionality 10 at each location. And suppose the 1x1 conv has, say, 20 nodes each doing a weighted sum of those 10 responses at each location. That is equivalent to doing 20 3x3 convolutions but in a much more efficient manner. This enables artificially increasing/reducing the number of kernels.\n",
    "\n",
    "A good example of what a 1x1 conv does is in steerable filters. Consider a Sobel kernel which has two kernels, the x-kernel and the y-kernel, meaning that the output has depth of 2, one for each kernel response. We can artificially increase the kernels by steering[1], that is, at each location we can sample a depth column of size 2 and do a weighted sum to produce say, 16 orientated kernels from just 2 basis kernels. We can also reduce the kernel count if, to start with, we had a large number of kernels using the same approach.\n",
    "\n",
    "Thus a 1x1 convolution does a linear combination of kernels to produce either a larger/smaller number of equivalent kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySsXckuWsHVh"
   },
   "source": [
    "#### 7. What are the advantages of a CNN over a fully connected DNN for this image classification problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gX9fbTmnsKzI"
   },
   "source": [
    "Convolutional Neural Networks are the basis of all modern computer vision models. Fully connected networks do not scale up past toy problems, because they use far too many parameters. CNNs are a much less flexible model compared to a fully connected network, and are biased toward performing well on image, because in images we would like to extract location invariant features.\n",
    "\n",
    "A face is a face no matter where it is located in an image. This is obvious to us, but a fully connected network must learn this property. CNNs encode this property, which is that we would like to extract the same features in an image, regardless of the where they are located. This means that we can learn the same feature extractor (the convolution) for every location in an image, which is a massive savings in parameters over a fully connected network, which would have to relearn the same feature extractor for each location.\n",
    "\n",
    "CNNs are also useful for 1D problems like time series, and 3D image classification, because they have the same structure where we would like location invariant features. Convolutions are technically location equivariant because they preserve the location of extracted features, but the important thing is that the same features are extracted over the entire image."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 8.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
