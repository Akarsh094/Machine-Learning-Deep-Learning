{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "## Akarsh Sahu\n",
    "### 10-23-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Import the data: shape should be (30000,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 24)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('credit.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1   24      2      2     -1     -1   \n",
       "1     120000    2          2         2   26     -1      2      0      0   \n",
       "2      90000    2          2         2   34      0      0      0      0   \n",
       "3      50000    2          2         1   37      0      0      0      0   \n",
       "4      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0     -2  ...          0          0          0         0       689         0   \n",
       "1      0  ...       3272       3455       3261         0      1000      1000   \n",
       "2      0  ...      14331      14948      15549      1518      1500      1000   \n",
       "3      0  ...      28314      28959      29547      2000      2019      1200   \n",
       "4      0  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "1      1000         0      2000                           1  \n",
       "2      1000      1000      5000                           0  \n",
       "3      1100      1069      1000                           0  \n",
       "4      9000       689       679                           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Remove any rows that have missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIMIT_BAL                     False\n",
       "SEX                           False\n",
       "EDUCATION                     False\n",
       "MARRIAGE                      False\n",
       "AGE                           False\n",
       "PAY_0                         False\n",
       "PAY_2                         False\n",
       "PAY_3                         False\n",
       "PAY_4                         False\n",
       "PAY_5                         False\n",
       "PAY_6                         False\n",
       "BILL_AMT1                     False\n",
       "BILL_AMT2                     False\n",
       "BILL_AMT3                     False\n",
       "BILL_AMT4                     False\n",
       "BILL_AMT5                     False\n",
       "BILL_AMT6                     False\n",
       "PAY_AMT1                      False\n",
       "PAY_AMT2                      False\n",
       "PAY_AMT3                      False\n",
       "PAY_AMT4                      False\n",
       "PAY_AMT5                      False\n",
       "PAY_AMT6                      False\n",
       "default payment next month    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) The target / y variable is \"default payment next month\" column. Keep all predictors for the X df except for the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['default payment next month']\n",
    "data.drop(['default payment next month'], axis = 1, inplace = True)\n",
    "X = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Split data into train / test set using an 70/30 split. Recall that you should be generating an X_train, X_test, y_train, and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(), test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest Classifier - Base Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Use the RandomForestClassifier in sklearn. Fit your model on the training data & make sure to add a random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akars\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mdl1 = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "mdl1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Use the fitted model to predict on test data. Use the .predict_proba() and the .predict() methods to get predicted probabilities as well as predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY_1 = mdl1.predict(X_test)\n",
    "predProb_1 = mdl1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Calculate the confusion matrix and classification report (both are in sklearn.metrics). These are the same tools from HW #3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      " [[6632  408]\n",
      " [1345  615]]\n",
      "\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      7040\n",
      "           1       0.60      0.31      0.41      1960\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      9000\n",
      "   macro avg       0.72      0.63      0.65      9000\n",
      "weighted avg       0.78      0.81      0.78      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "\n",
    "#Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, predY_1)\n",
    "print(\"Confusion Matrix\\n\\n\", cnf_matrix)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "#Classification Report\n",
    "cl_report = metrics.classification_report(y_test, predY_1)\n",
    "print(\"Classification Report\\n\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names);\n",
    "plt.yticks(tick_marks, class_names);\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g');\n",
    "ax.xaxis.set_label_position(\"top\");\n",
    "plt.tight_layout();\n",
    "plt.title('Confusion matrix', y=1.1);\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Calculate the roc_auc_score for this model. There are many ways to do this, but an example is to use the probabilities from step B and utilize the roc_auc_score from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.627910482374768"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, predY_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Calculate predictions for the training data & build the classification report & roc_auc_score. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY_tr_1 = mdl1.predict(X_train)\n",
    "predProb_tr_1 = mdl1.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      " [[16297    27]\n",
      " [  396  4280]]\n",
      "\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     16324\n",
      "           1       0.99      0.92      0.95      4676\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     21000\n",
      "   macro avg       0.99      0.96      0.97     21000\n",
      "weighted avg       0.98      0.98      0.98     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "\n",
    "#Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_train, predY_tr_1)\n",
    "print(\"Confusion Matrix\\n\\n\", cnf_matrix)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "#Classification Report\n",
    "cl_report = metrics.classification_report(y_train, predY_tr_1)\n",
    "print(\"Classification Report\\n\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9568291131532575"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_train, predY_tr_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the precision,recall, and f1 score are pretty hight in training dataset as compared to the test set. Also, the ROC curve is 95% in train set. Hence, there is a sign of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest Classifier - Grid Search:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Use the RandomForestClassifier along with the GridSearchCV tool. Run the GridSearchCV using the following: \n",
    "\n",
    "1. n_estimators: 50, 100, 500\n",
    "2. max_features: 2, 4, sqrt\n",
    "3. max_depth: 6, 8, 10, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#create a dictionary of parameters \n",
    "param_grid = {\n",
    "    'max_depth': [2,4,6,8,10],\n",
    "    'min_samples_split': [3,4,5,6,7,8],\n",
    "    'n_estimators': [50, 100, 500],\n",
    "    'max_features': [2,4,6]\n",
    "}\n",
    "\n",
    "# create Random Forest model \n",
    "rf_obj=RandomForestClassifier()\n",
    "\n",
    "# Create gridsearch object with various combinations of parameters\n",
    "rf_Grid = GridSearchCV(rf_obj, param_grid, cv = 5, scoring = 'roc_auc',refit = True, n_jobs=-1, verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1350 out of 1350 | elapsed: 25.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [2, 4, 6, 8, 10], 'min_samples_split': [3, 4, 5, 6, 7, 8], 'n_estimators': [50, 100, 500], 'max_features': [2, 4, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "rf_Grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Identify the best performing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 4,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mdl = rf_Grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Use the best estimator model to predict on test data. Use the .predict_proba() and the .predict() methods to get predicted probabilities as well as predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY_2 = best_mdl.predict(X_test)\n",
    "predProb_2 = best_mdl.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Calculate the confusion matrix and classification report (both are in sklearn.metrics). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      " [[6689  351]\n",
      " [1268  692]]\n",
      "\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      7040\n",
      "           1       0.66      0.35      0.46      1960\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      9000\n",
      "   macro avg       0.75      0.65      0.68      9000\n",
      "weighted avg       0.80      0.82      0.80      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "\n",
    "#Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, predY_2)\n",
    "print(\"Confusion Matrix\\n\\n\", cnf_matrix)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "#Classification Report\n",
    "cl_report = metrics.classification_report(y_test, predY_2)\n",
    "print(\"Classification Report\\n\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Calculate the roc_auc_score for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6516016349721707"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, predY_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Calculate predictions for the training data & build the confusion matrix, classification report & roc_auc_score. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY_tr_2 = best_mdl.predict(X_train)\n",
    "predProb_tr_2 = best_mdl.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      " [[15886   438]\n",
      " [ 2582  2094]]\n",
      "\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91     16324\n",
      "           1       0.83      0.45      0.58      4676\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     21000\n",
      "   macro avg       0.84      0.71      0.75     21000\n",
      "weighted avg       0.85      0.86      0.84     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "\n",
    "#Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_train, predY_tr_2)\n",
    "print(\"Confusion Matrix\\n\\n\", cnf_matrix)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "#Classification Report\n",
    "cl_report = metrics.classification_report(y_train, predY_tr_2)\n",
    "print(\"Classification Report\\n\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7104934947551602"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_train, predY_tr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics precision, recall, and f1 score for train dataset are comparable to that of test dataset. Also, the AUC of the train dataset is 71% as compared to 65% AUC of the test dataset. Hence, there is not overfitting as such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a feature importance plot for your best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) What are the top 5 features for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(best_mdl.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(5).plot(kind='barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conceptual Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) What are the best parameters from the Grid Search in Question # 3? Does the Model from #3 outperform Model #2? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters from the Grid Search:\n",
    "\n",
    "bootstrap=True, class_weight=None, criterion='gini', max_depth=10, max_features=4, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=8, min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False\n",
    "            \n",
    "The model from #3 slightly outperformed Model from #2. The roc_auc_score, classification report and confusion matrix for model #3 on the test data is better than that of model #2. This was possible because model #3 was tuned using grid search which performed the hyperparameter (characteristic of a model that is external to the model and whose value cannot be estimated from data and set prior to the commencement of a learning process) tunings to determine the optimal values (but not always, depending on what parameter choices are provided) for the Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Overfitting is always a concern in ML problems. Does Model #3 overfit data more or less than Model #2? Explain why you think this is the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model #3 overfit the data LESS than Model #2. As mentioned above, the grid search performed an exhaustive search (for this assignmend the parameters provided was not exhaustive but still better than the default in Model #2) and found the optimal ways to tune the hyperparemeters based on the training set. Which provided us with a \"better\" model - because we \"contolled\" the values of the hyperparameters. Whereas, Model 2, which used the default settings, fitted the train data too well (the model got most of the patterns from the dataset), resulted in more severe overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) The lecture notes describe the Gini Index which is the default criterion used for splitting in sklearn's version of RandomForestClassifier. How does the Gini Index work? (i.e. How is it used to build a top-performing model?). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lecture notes describe the Gini Index which is the default criterion used for splitting in sklearn's version of RandomForestClassifier. How does the Gini Index work? (i.e. How is it used to build a top-performing model?).\n",
    "Random Forest technically is an ensemble method of decision trees generated on a randomly split dataset where the individual decision trees are generated using an attribute selection indicator such as information gain, gain ratio, and Gini index for each attribute. Gini Index is used to build a top performing model for Random forests by allowing it to find \"important features\" which shows the relative importance or contribution of each feature in the prediction. This helps to choose the most important features and drop the least important ones for model building. Random Forest uses the gini importance or mean decrease in impurity (MDI) to calculate the importance of each feature. Gini importance is also known as the total decrease in node impurity. This is how much the model fit or accuracy decreases when you drop a variable. The Gini index can describe the overall explanatory power of the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Describe how Random Forest is different from bagging & why this difference can yield improved results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Random Forest is an ensemble of Decision Trees, generally trained via the bagging method. So bagging and random forests are â€œbaggingâ€ algorithms that aim to reduce the complexity of models that overfit the training data. But one of the fundamental difference is that in Random forests, only a subset of features are selected at random out of the total and the best split feature from the subset is used to split each node in a tree, unlike in bagging where all features are considered for splitting a node.\n",
    "\n",
    "Due to the random feature selection, the trees are more independent of each other compared to regular bagging. Meaning Random Forest algorithm introduces extra randomness when growing trees. Instead of searching for the very best feature when splitting a node, it searches for the best feature among a random subset of features. This results in a greater tree diversity, which trades a higher bias for a lower variance, generally yielding an overall better predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Describe the importance of the max_depth parameter in Random Forest. Do not just provide a definition, rather think through how bias-variance tradeoff might be impacted by the max_depth parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth represents the depth of each tree in the forest. The deeper the tree, the more splits it has and it captures more information about the data. This can be used to reduce the complexity of the learned models, lowering over fitting risk. Limiting the max_depth has the consequence that the Random Forest can no more fit the training data as closely, and is consequently more stable. It has lower variance, giving our model lower error. However, severely constraining max_depth could increase the bias of each tree given that they may not be able to capture certain patterns in the data before hitting their limit. So finding the balance and choosing a suitable max_depth comes with the tradeoff between bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) In this homework we used k-fold cross-validation while determining the optimal hyperparameters for our Random Forest model. \n",
    "1) Describe how k-fold cross-validation works. \n",
    "2) What benefit do we gain by using k-fold cross-validation when tuning our Random Forest model versus only using the train-test split approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample. The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation. Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data.\n",
    "\n",
    "How it works (in general):\n",
    "\n",
    "1. Shuffle the dataset randomly.\n",
    "2. Split the dataset into k groups\n",
    "3. For each unique group:\n",
    "4. Take the group as a hold out or test data set\n",
    "5. Take the remaining groups as a training data set\n",
    "6. Fit a model on the training set and evaluate it on the test set\n",
    "7. Retain the evaluation score and discard the model\n",
    "8. Summarize the skill of the model using the sample of model evaluation scores\n",
    "\n",
    "\n",
    "The primary object and benefit of using k-fold cross-validation while determining the optimal hyperparameters for our Random Forest model is to choose different partitions of the data, and then average the result, so that the result will not be biased by any single partition. i.e. for hyperparameter tuning for this tuning our random forest model, we perform many iterations of the entire K-Fold CV process, each time using different model settings. We then compared all of the models, selected the best one, train it on the full training set, and then evaluate on the testing set. This processed gave us an overall better predictive performance for our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
